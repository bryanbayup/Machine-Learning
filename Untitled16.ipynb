{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMbEEo81Qv/1H8kdvBEmFOV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3fe118347f5a419d8779b67d8901a013": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Anda:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_34737249966241bab001add9ea811a6c",
            "placeholder": "Ketik pesan Anda...",
            "style": "IPY_MODEL_f2ea709234ea4ab1b6c3a70da5af8ec6",
            "value": ""
          }
        },
        "34737249966241bab001add9ea811a6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2ea709234ea4ab1b6c3a70da5af8ec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2168ca5a2cef4f7488224b2996976a90": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_bf28a4b7cd244fa4b8401ee07546c035",
            "msg_id": "",
            "outputs": []
          }
        },
        "bf28a4b7cd244fa4b8401ee07546c035": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bryanbayup/Machine-Learning/blob/main/Untitled16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seqeval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZQPooANmiDr",
        "outputId": "ff2e0476-5292-4a3c-b07f-c23220a87d79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.5.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.5.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=1dbd856f17545121abc60765d01a42b66f2643984d766965b6320e3ab581e730\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import re\n",
        "from sklearn.utils import resample\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from seqeval.metrics import classification_report as seq_classification_report\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import random\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output"
      ],
      "metadata": {
        "id": "VOeM3A4OmZRw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Memuat dataset dari file JSON\n",
        "with open('dataaa.json', 'r', encoding='utf-8') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Mengubah dataset menjadi DataFrame\n",
        "df = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "_xgybeKSxxbM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menentukan jumlah sampel maksimum per intent\n",
        "max_samples = 50\n",
        "\n",
        "df_list = []\n",
        "for intent in df['intent'].unique():\n",
        "    df_intent = df[df['intent'] == intent]\n",
        "    if len(df_intent) > max_samples:\n",
        "        df_intent = resample(df_intent, replace=False, n_samples=max_samples, random_state=42)\n",
        "    df_list.append(df_intent)\n",
        "\n",
        "df_balanced = pd.concat(df_list).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "fksn_wdOx1Yl"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Periksa distribusi kelas\n",
        "class_counts = df_balanced['intent'].value_counts()\n",
        "print(\"Distribusi kelas sebelum penyesuaian:\")\n",
        "print(class_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mEu8cuZ4z9Gm",
        "outputId": "9cbe47c8-4ea3-4110-a2a7-a8db5c438444"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribusi kelas sebelum penyesuaian:\n",
            "intent\n",
            "medical_inquiry_dog       50\n",
            "disease_prevention_cat    50\n",
            "general_conversation      50\n",
            "medical_inquiry_cat       50\n",
            "philosophical_question    42\n",
            "                          ..\n",
            "cat_diet                   1\n",
            "dog_stress_signs           1\n",
            "cat_cleaning               1\n",
            "dog_bathing                1\n",
            "financial_crisis           1\n",
            "Name: count, Length: 64, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gandakan sampel untuk kelas dengan hanya 1 sampel\n",
        "classes_with_one_sample = class_counts[class_counts == 1].index.tolist()\n",
        "for cls in classes_with_one_sample:\n",
        "    df_class = df_balanced[df_balanced['intent'] == cls]\n",
        "    df_balanced = pd.concat([df_balanced, df_class])  # Menggandakan sampel"
      ],
      "metadata": {
        "id": "xY486yLv0AbB"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Periksa kembali distribusi kelas\n",
        "class_counts = df_balanced['intent'].value_counts()\n",
        "print(\"\\nDistribusi kelas setelah penyesuaian:\")\n",
        "print(class_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYQqaSEp0DiA",
        "outputId": "f3363590-d72d-4b48-832b-0b83611edc15"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Distribusi kelas setelah penyesuaian:\n",
            "intent\n",
            "medical_inquiry_dog       50\n",
            "disease_prevention_cat    50\n",
            "general_conversation      50\n",
            "medical_inquiry_cat       50\n",
            "philosophical_question    42\n",
            "                          ..\n",
            "cat_diet                   2\n",
            "dog_stress_signs           2\n",
            "cat_cleaning               2\n",
            "dog_bathing                2\n",
            "financial_crisis           2\n",
            "Name: count, Length: 64, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode intents\n",
        "label_encoder = LabelEncoder()\n",
        "df_balanced['intent_label'] = label_encoder.fit_transform(df_balanced['intent'])\n",
        "\n",
        "# Simpan mapping label untuk penggunaan nanti\n",
        "intent_mapping = dict(zip(df_balanced['intent_label'], df_balanced['intent']))"
      ],
      "metadata": {
        "id": "4ZoM06oo0H8q"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Memfilter data yang memiliki entitas\n",
        "df_ner = df[df['entities'].map(lambda d: len(d)) > 0].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "Ptw6PXnO0RSH"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "uWZivlfw0UQQ"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = df_balanced['utterances'].apply(clean_text).tolist()\n",
        "labels = df_balanced['intent_label'].tolist()\n",
        "\n",
        "# Split the data\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    texts,\n",
        "    labels,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=labels\n",
        ")"
      ],
      "metadata": {
        "id": "y9vUUerB0WEM"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat tokenizer\n",
        "tokenizer = Tokenizer(oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(train_texts)\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(word_index) + 1\n",
        "\n",
        "# Mengonversi teks ke sequences\n",
        "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
        "val_sequences = tokenizer.texts_to_sequences(val_texts)\n",
        "\n",
        "# Padding sequences\n",
        "max_seq_length = max(max(len(seq) for seq in train_sequences), max(len(seq) for seq in val_sequences))\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_seq_length, padding='post')\n",
        "val_padded = pad_sequences(val_sequences, maxlen=max_seq_length, padding='post')\n",
        "\n",
        "# Mengonversi labels ke categorical\n",
        "num_classes = len(label_encoder.classes_)\n",
        "train_labels_cat = to_categorical(train_labels, num_classes=num_classes)\n",
        "val_labels_cat = to_categorical(val_labels, num_classes=num_classes)"
      ],
      "metadata": {
        "id": "nWMvZIhH0Yc3"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_ner_data(df, tokenizer, max_seq_length):\n",
        "    texts = []\n",
        "    labels = []\n",
        "    for index, row in df.iterrows():\n",
        "        text = clean_text(row['utterances'])\n",
        "        entities = row['entities']\n",
        "        tokens = tokenizer.texts_to_sequences([text])[0]\n",
        "        label_seq = ['O'] * len(tokens)\n",
        "        for ent in entities:\n",
        "            ent_text = clean_text(ent['value'])\n",
        "            ent_tokens = tokenizer.texts_to_sequences([ent_text])[0]\n",
        "            for i in range(len(tokens)):\n",
        "                if tokens[i:i+len(ent_tokens)] == ent_tokens:\n",
        "                    label_seq[i] = 'B-' + ent['entity']\n",
        "                    for j in range(1, len(ent_tokens)):\n",
        "                        label_seq[i+j] = 'I-' + ent['entity']\n",
        "                    break\n",
        "        texts.append(tokens)\n",
        "        labels.append(label_seq)\n",
        "    # Padding\n",
        "    texts_padded = pad_sequences(texts, maxlen=max_seq_length, padding='post')\n",
        "    return texts_padded, labels\n",
        "\n",
        "# Membuat label encoder untuk NER\n",
        "all_labels = set()\n",
        "for label_list in df_ner['entities']:\n",
        "    for ent in label_list:\n",
        "        all_labels.add('B-' + ent['entity'])\n",
        "        all_labels.add('I-' + ent['entity'])\n",
        "all_labels.add('O')\n",
        "ner_label_encoder = {label: idx for idx, label in enumerate(sorted(all_labels))}\n",
        "ner_label_decoder = {idx: label for label, idx in ner_label_encoder.items()}\n",
        "\n",
        "# Siapkan data NER\n",
        "texts_ner = df_ner['utterances'].apply(clean_text).tolist()\n",
        "labels_ner = df_ner['entities'].tolist()\n",
        "\n",
        "texts_ner_prep, labels_ner_prep = prepare_ner_data(df_ner, tokenizer, max_seq_length)\n",
        "\n",
        "# Mengonversi labels ke format numerik\n",
        "def encode_ner_labels(labels, max_seq_length, ner_label_encoder):\n",
        "    labels_encoded = []\n",
        "    for label_seq in labels:\n",
        "        label_ids = [ner_label_encoder[label] for label in label_seq]\n",
        "        label_ids = label_ids + [ner_label_encoder['O']] * (max_seq_length - len(label_ids))\n",
        "        labels_encoded.append(label_ids)\n",
        "    labels_encoded = np.array(labels_encoded)\n",
        "    labels_encoded = to_categorical(labels_encoded, num_classes=len(ner_label_encoder))\n",
        "    return labels_encoded\n",
        "\n",
        "labels_ner_encoded = encode_ner_labels(labels_ner_prep, max_seq_length, ner_label_encoder)"
      ],
      "metadata": {
        "id": "zLDA28FV0a25"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data\n",
        "train_texts_ner, val_texts_ner, train_labels_ner, val_labels_ner = train_test_split(\n",
        "    texts_ner_prep,\n",
        "    labels_ner_encoded,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "bVKKrLF30db7"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Dropout, BatchNormalization\n",
        "\n",
        "model_intent = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=256, input_length=max_seq_length),\n",
        "    Bidirectional(LSTM(128, return_sequences=True)),\n",
        "    Dropout(0.5),\n",
        "    Bidirectional(LSTM(64)),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model_intent.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVP6HyZX0f4z",
        "outputId": "04f239ee-edd7-4af2-f00a-89d5994fa9a6"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
        "    ModelCheckpoint(\n",
        "        filepath='best_model_intent.weights.h5',\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True\n",
        "    )\n",
        "]\n",
        "\n",
        "history_intent = model_intent.fit(\n",
        "    train_padded,\n",
        "    train_labels_cat,\n",
        "    validation_data=(val_padded, val_labels_cat),\n",
        "    epochs=20,\n",
        "    batch_size=16,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcUdt3i50iQu",
        "outputId": "5d36c69f-5f84-40a1-da0e-c92641f9d3d8"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.9785 - loss: 0.1031 - val_accuracy: 0.8718 - val_loss: 0.4766\n",
            "Epoch 2/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.9766 - loss: 0.1232 - val_accuracy: 0.8376 - val_loss: 0.7149\n",
            "Epoch 3/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - accuracy: 0.9653 - loss: 0.1039 - val_accuracy: 0.8205 - val_loss: 0.6497\n",
            "Epoch 4/20\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 135ms/step - accuracy: 0.9846 - loss: 0.1308 - val_accuracy: 0.8632 - val_loss: 0.6110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import TimeDistributed, Bidirectional, Dense, LSTM, Embedding, Dropout\n",
        "\n",
        "model_ner = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=256, input_length=max_seq_length),\n",
        "    Bidirectional(LSTM(128, return_sequences=True)),\n",
        "    Dropout(0.5),\n",
        "    Bidirectional(LSTM(64, return_sequences=True)),\n",
        "    Dropout(0.5),\n",
        "    TimeDistributed(Dense(len(ner_label_encoder), activation='softmax'))\n",
        "])\n",
        "\n",
        "model_ner.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "5Oi898Jt0nVb"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks\n",
        "callbacks_ner = [\n",
        "    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
        "    ModelCheckpoint(\n",
        "        filepath='best_model_ner..weights.h5',\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True\n",
        "    )\n",
        "]\n",
        "\n",
        "history_ner = model_ner.fit(\n",
        "    train_texts_ner,\n",
        "    train_labels_ner,\n",
        "    validation_data=(val_texts_ner, val_labels_ner),\n",
        "    epochs=20,\n",
        "    batch_size=16,\n",
        "    callbacks=callbacks_ner\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLlt9A1A17RZ",
        "outputId": "ae9ef602-c1dc-43cb-8680-6cbf7fa6d93b"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.9342 - loss: 0.2138 - val_accuracy: 0.8941 - val_loss: 0.3175\n",
            "Epoch 2/20\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - accuracy: 0.9340 - loss: 0.1976 - val_accuracy: 0.9057 - val_loss: 0.3149\n",
            "Epoch 3/20\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.9487 - loss: 0.1713 - val_accuracy: 0.9046 - val_loss: 0.3136\n",
            "Epoch 4/20\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 111ms/step - accuracy: 0.9382 - loss: 0.1753 - val_accuracy: 0.9088 - val_loss: 0.3008\n",
            "Epoch 5/20\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 146ms/step - accuracy: 0.9512 - loss: 0.1511 - val_accuracy: 0.9015 - val_loss: 0.3136\n",
            "Epoch 6/20\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 82ms/step - accuracy: 0.9584 - loss: 0.1298 - val_accuracy: 0.9099 - val_loss: 0.3124\n",
            "Epoch 7/20\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9571 - loss: 0.1322 - val_accuracy: 0.9109 - val_loss: 0.3241\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load best weights\n",
        "model_intent.load_weights('best_model_intent.weights.h5')\n",
        "\n",
        "# Evaluasi\n",
        "loss, accuracy = model_intent.evaluate(val_padded, val_labels_cat)\n",
        "print(f'Akurasi Model Klasifikasi Intent: {accuracy * 100:.2f}%')\n",
        "\n",
        "# Predict on validation data\n",
        "val_preds = model_intent.predict(val_padded)\n",
        "val_preds = np.argmax(val_preds, axis=1)\n",
        "val_true = np.argmax(val_labels_cat, axis=1)\n",
        "\n",
        "# Get unique labels present in val_true\n",
        "unique_labels = np.unique(val_true)\n",
        "\n",
        "# Filter label_encoder.classes_ to include only the present labels\n",
        "target_names = [label_encoder.classes_[i] for i in unique_labels]\n",
        "\n",
        "\n",
        "# Classification report\n",
        "# Use 'labels' parameter to specify the classes for the report\n",
        "print(classification_report(val_true, val_preds, labels=unique_labels, target_names=target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUZoaQb819YP",
        "outputId": "61f503e8-806e-4859-83f4-6dce2d18582e"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8821 - loss: 0.4288\n",
            "Akurasi Model Klasifikasi Intent: 87.18%\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "       bot_capabilities       1.00      1.00      1.00         1\n",
            "            bot_emotion       1.00      1.00      1.00         1\n",
            "       business_startup       1.00      1.00      1.00         1\n",
            "           cat_cleaning       1.00      1.00      1.00         1\n",
            "               cat_diet       1.00      1.00      1.00         1\n",
            "         cat_healthcare       1.00      1.00      1.00         6\n",
            "        debt_management       0.00      0.00      0.00         1\n",
            " disease_prevention_cat       1.00      1.00      1.00        10\n",
            " disease_prevention_dog       0.89      1.00      0.94         8\n",
            "            dog_bathing       1.00      1.00      1.00         1\n",
            "dog_behavior_management       1.00      1.00      1.00         1\n",
            "  dog_biting_prevention       1.00      1.00      1.00         1\n",
            "         dog_healthcare       1.00      0.88      0.93         8\n",
            "       financial_basics       0.50      0.75      0.60         4\n",
            "       financial_crisis       1.00      1.00      1.00         1\n",
            "   general_conversation       1.00      0.90      0.95        10\n",
            "               greeting       1.00      0.67      0.80         3\n",
            "        investment_tips       0.00      0.00      0.00         1\n",
            "            kitten_care       1.00      1.00      1.00         1\n",
            "     long_hair_cat_care       1.00      1.00      1.00         1\n",
            "    medical_inquiry_cat       0.91      1.00      0.95        10\n",
            "    medical_inquiry_dog       1.00      1.00      1.00        10\n",
            "       personal_finance       0.00      0.00      0.00         1\n",
            "pet_health_status_check       0.00      0.00      0.00         2\n",
            " philosophical_question       0.78      0.78      0.78         9\n",
            "         puppy_training       1.00      1.00      1.00         1\n",
            "            saving_tips       0.00      0.00      0.00         1\n",
            "   science_conversation       0.70      0.88      0.78         8\n",
            "   symptom_analysis_cat       1.00      0.75      0.86         4\n",
            "   symptom_analysis_dog       0.80      1.00      0.89         4\n",
            "             user_anger       0.00      0.00      0.00         1\n",
            "         user_apologize       1.00      1.00      1.00         1\n",
            "         user_complaint       1.00      1.00      1.00         1\n",
            "         user_giving_up       1.00      1.00      1.00         1\n",
            "          user_thankful       1.00      1.00      1.00         1\n",
            "\n",
            "              micro avg       0.90      0.87      0.89       117\n",
            "              macro avg       0.79      0.79      0.79       117\n",
            "           weighted avg       0.86      0.87      0.86       117\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load best weights\n",
        "model_ner.load_weights('best_model_ner..weights.h5')\n",
        "\n",
        "# Evaluasi\n",
        "loss, accuracy = model_ner.evaluate(val_texts_ner, val_labels_ner)\n",
        "print(f'Akurasi Model NER: {accuracy * 100:.2f}%')\n",
        "\n",
        "# Predict on validation data\n",
        "val_preds = model_ner.predict(val_texts_ner)\n",
        "val_preds = np.argmax(val_preds, axis=-1)\n",
        "val_true = np.argmax(val_labels_ner, axis=-1)\n",
        "\n",
        "# Konversi label ke format aslinya\n",
        "true_labels = []\n",
        "pred_labels = []\n",
        "\n",
        "for i in range(len(val_preds)):\n",
        "    true_label = []\n",
        "    pred_label = []\n",
        "    for j in range(len(val_preds[i])):\n",
        "        true_l = ner_label_decoder[val_true[i][j]]\n",
        "        pred_l = ner_label_decoder[val_preds[i][j]]\n",
        "        if true_l != 'O':\n",
        "            true_label.append(true_l)\n",
        "            pred_label.append(pred_l)\n",
        "    true_labels.append(true_label)\n",
        "    pred_labels.append(pred_label)\n",
        "\n",
        "# Classification report\n",
        "print(seq_classification_report(true_labels, pred_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0i12yx_2Wlc",
        "outputId": "38206d3a-3c0b-4c52-e2b9-438713dc4ad0"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9074 - loss: 0.3089 \n",
            "Akurasi Model NER: 90.88%\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      animal       0.94      0.94      0.94        35\n",
            "    behavior       0.00      0.00      0.00         1\n",
            "     disease       0.72      0.68      0.70        19\n",
            "    duration       0.00      0.00      0.00         2\n",
            "        food       0.00      0.00      0.00         1\n",
            "     symptom       0.47      0.38      0.42        42\n",
            "\n",
            "   micro avg       0.71      0.62      0.66       100\n",
            "   macro avg       0.36      0.33      0.34       100\n",
            "weighted avg       0.66      0.62      0.64       100\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simpan model dan tokenizer\n",
        "model_intent.save('model_intent.h5')\n",
        "model_ner.save('model_ner.h5')\n",
        "\n",
        "import pickle\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('label_encoder.pickle', 'wb') as handle:\n",
        "    pickle.dump(label_encoder, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('ner_label_encoder.pickle', 'wb') as handle:\n",
        "    pickle.dump(ner_label_encoder, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjqVv7nv3J0N",
        "outputId": "2bff17fe-ece5-4202-f6e2-8f903f7f0a81"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Memuat model dan tokenizer\n",
        "from tensorflow.keras.models import load_model\n",
        "model_intent = load_model('model_intent.h5')\n",
        "model_ner = load_model('model_ner.h5')\n",
        "\n",
        "import pickle\n",
        "with open('tokenizer.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)\n",
        "with open('label_encoder.pickle', 'rb') as handle:\n",
        "    label_encoder = pickle.load(handle)\n",
        "with open('ner_label_encoder.pickle', 'rb') as handle:\n",
        "    ner_label_encoder = pickle.load(handle)\n",
        "ner_label_decoder = {idx: label for label, idx in ner_label_encoder.items()}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8i0gORZb3U-f",
        "outputId": "3de540b4-ff93-4f03-f924-b0831749615b"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_intent(text):\n",
        "    text_clean = clean_text(text)\n",
        "    seq = tokenizer.texts_to_sequences([text_clean])\n",
        "    padded_seq = pad_sequences(seq, maxlen=max_seq_length, padding='post')\n",
        "    pred = model_intent.predict(padded_seq)\n",
        "    predicted_label = np.argmax(pred, axis=1)[0]\n",
        "    intent = label_encoder.inverse_transform([predicted_label])[0]\n",
        "    return intent"
      ],
      "metadata": {
        "id": "TupPhX4m3Xhi"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_entities(text):\n",
        "    text_clean = clean_text(text)\n",
        "    seq = tokenizer.texts_to_sequences([text_clean])\n",
        "    padded_seq = pad_sequences(seq, maxlen=max_seq_length, padding='post')\n",
        "    pred = model_ner.predict(padded_seq)\n",
        "    pred_labels = np.argmax(pred, axis=-1)[0]\n",
        "    tokens = tokenizer.sequences_to_texts(seq)[0].split()\n",
        "    entities = []\n",
        "    for idx, label_id in enumerate(pred_labels[:len(tokens)]):\n",
        "        label = ner_label_decoder[label_id]\n",
        "        if label != 'O':\n",
        "            entities.append({'entity': label.split('-')[1], 'value': tokens[idx]})\n",
        "    return entities"
      ],
      "metadata": {
        "id": "ubXminGI3aX2"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mendefinisikan model tanpa layer output untuk mendapatkan embedding\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "embedding_model = Model(inputs=model_intent.input, outputs=model_intent.layers[-3].output)\n",
        "\n",
        "# Mendapatkan embedding dari dataset\n",
        "utterance_embeddings = embedding_model.predict(train_padded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "aZXcBiJD3cXC",
        "outputId": "df29fd3b-5763-409f-aa99-3609ae63832c"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The layer sequential has never been called and thus has no defined input.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-4a1addb14fb8>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0membedding_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_intent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_intent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Mendapatkan embedding dari dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36minput\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0mInput\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0minput\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \"\"\"\n\u001b[0;32m--> 254\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_node_attribute_at_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"input_tensors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/ops/operation.py\u001b[0m in \u001b[0;36m_get_node_attribute_at_index\u001b[0;34m(self, node_index, attr, attr_name)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \"\"\"\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    286\u001b[0m                 \u001b[0;34mf\"The layer {self.name} has never been called \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m                 \u001b[0;34mf\"and thus has no defined {attr_name}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The layer sequential has never been called and thus has no defined input."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def get_response(user_input):\n",
        "    # Preprocess input\n",
        "    text_clean = clean_text(user_input)\n",
        "    seq = tokenizer.texts_to_sequences([text_clean])\n",
        "    padded_seq = pad_sequences(seq, maxlen=max_seq_length, padding='post')\n",
        "\n",
        "    # Mendapatkan embedding input pengguna\n",
        "    user_embedding = embedding_model.predict(padded_seq)\n",
        "\n",
        "    # Menghitung kemiripan\n",
        "    similarities = cosine_similarity(user_embedding, utterance_embeddings)\n",
        "\n",
        "    # Dapatkan indeks dengan similarity tertinggi\n",
        "    most_similar_idx = np.argmax(similarities[0])\n",
        "\n",
        "    # Jika similarity rendah, berikan respon default\n",
        "    if similarities[0][most_similar_idx] < 0.5:\n",
        "        return \"Maaf, saya tidak memahami pertanyaan Anda.\"\n",
        "\n",
        "    # Ambil respon yang sesuai\n",
        "    response = df_balanced.iloc[most_similar_idx]['responses']\n",
        "\n",
        "    return response"
      ],
      "metadata": {
        "id": "CWZTEPCj3ehh"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "\n",
        "def google_search(query):\n",
        "    service = build(\"customsearch\", \"v1\", developerKey=\"AIzaSyD-f-0S98J0bcdG_5AvbuNGSBVHIgQIX1Y\")\n",
        "    res = service.cse().list(q=query, cx='30b6a924536894083').execute()\n",
        "    results = res.get('items', [])\n",
        "    if results:\n",
        "        snippet = results[0]['snippet']\n",
        "        return snippet\n",
        "    else:\n",
        "        return \"Maaf, saya tidak menemukan informasi yang Anda cari.\""
      ],
      "metadata": {
        "id": "qvrCCGPX3t9l"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot_response(user_input):\n",
        "    # Prediksi intent dan entitas\n",
        "    intent = predict_intent(user_input)\n",
        "    entities = predict_entities(user_input)\n",
        "\n",
        "    # Jika intent tidak dikenali, gunakan Google Search\n",
        "    if intent == 'general_conversation':\n",
        "        response = get_response(user_input)\n",
        "    else:\n",
        "        # Gunakan Google Search untuk mendapatkan informasi tambahan\n",
        "        query = user_input\n",
        "        search_result = google_search(query)\n",
        "        response = f\"{get_response(user_input)}\\n\\nInformasi tambahan:\\n{search_result}\"\n",
        "\n",
        "    return response"
      ],
      "metadata": {
        "id": "hlqx3Ino3yWs"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat widget input dan output\n",
        "input_box = widgets.Text(\n",
        "    value='',\n",
        "    placeholder='Ketik pesan Anda...',\n",
        "    description='Anda:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "output_area = widgets.Output()\n",
        "\n",
        "def on_submit(sender):\n",
        "    user_input = input_box.value\n",
        "    input_box.value = ''\n",
        "    response = chatbot_response(user_input)\n",
        "    with output_area:\n",
        "        print(f\"Anda: {user_input}\")\n",
        "        print(f\"Chatbot: {response}\\n\")\n",
        "\n",
        "input_box.on_submit(on_submit)\n",
        "\n",
        "display(input_box, output_area)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50,
          "referenced_widgets": [
            "3fe118347f5a419d8779b67d8901a013",
            "34737249966241bab001add9ea811a6c",
            "f2ea709234ea4ab1b6c3a70da5af8ec6",
            "2168ca5a2cef4f7488224b2996976a90",
            "bf28a4b7cd244fa4b8401ee07546c035"
          ]
        },
        "id": "_OYdd9k937Z8",
        "outputId": "c30c6482-3c59-4b76-ae05-7a06e73e080b"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Text(value='', description='Anda:', placeholder='Ketik pesan Anda...')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3fe118347f5a419d8779b67d8901a013"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2168ca5a2cef4f7488224b2996976a90"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Contoh kalimat\n",
        "test_sentence = \"Kucing saya sering muntah dan tidak mau makan.\"\n",
        "\n",
        "# Prediksi intent\n",
        "predicted_intent = predict_intent(test_sentence)\n",
        "print(f\"Intent yang diprediksi: {predicted_intent}\")\n",
        "\n",
        "# Prediksi entitas\n",
        "predicted_entities = predict_entities(test_sentence)\n",
        "print(\"Entitas yang ditemukan:\")\n",
        "for entity in predicted_entities:\n",
        "    print(f\"- {entity['entity']}: {entity['value']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYbVqgXJ4M90",
        "outputId": "237ddd91-4b90-4843-ec62-7e2d3073bf8c"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 902ms/step\n",
            "Intent yang diprediksi: symptom_analysis_cat\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7c07d9b04b80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "Entitas yang ditemukan:\n",
            "- animal: kucing\n",
            "- symptom: sering\n",
            "- symptom: muntah\n",
            "- symptom: tidak\n",
            "- symptom: mau\n",
            "- symptom: makan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mendapatkan respon\n",
        "response = chatbot_response(test_sentence)\n",
        "print(f\"Chatbot: {response}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "EWcAGj2k4Pwu",
        "outputId": "5d4273ce-a8f4-45ff-c6bc-eeab5d95aedf"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'embedding_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-9633f0d7acdc>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Mendapatkan respon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchatbot_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Chatbot: {response}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-65-4cf5e1bba47c>\u001b[0m in \u001b[0;36mchatbot_response\u001b[0;34m(user_input)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0msearch_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgoogle_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{get_response(user_input)}\\n\\nInformasi tambahan:\\n{search_result}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-61-35359f3da977>\u001b[0m in \u001b[0;36mget_response\u001b[0;34m(user_input)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Mendapatkan embedding input pengguna\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0muser_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Menghitung kemiripan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'embedding_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3Jl7K7oR4UF6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}