{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNNWIJmCgl2OYySX9vcHoG8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d2e0db013ee24a1ca7c7b2818732afa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Anda:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_932d1e9f7e4944b2972acc0926f9e7e7",
            "placeholder": "Ketik pesan Anda...",
            "style": "IPY_MODEL_3963618285d54ca0b0375c7e4f6b3175",
            "value": ""
          }
        },
        "932d1e9f7e4944b2972acc0926f9e7e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3963618285d54ca0b0375c7e4f6b3175": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7797962f35948f7ae1ca4ed5ffebb85": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_bfbb887014e64ad9b11cd4e3d4ad352f",
            "msg_id": "",
            "outputs": []
          }
        },
        "bfbb887014e64ad9b11cd4e3d4ad352f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bryanbayup/Machine-Learning/blob/main/Untitled16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seqeval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZQPooANmiDr",
        "outputId": "bef8096a-c097-4989-db6a-c730b35be338"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.5.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.5.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=912ca779c830082e181c7b354cb2a42fd9a22e956a15ce2fb183603956472a8c\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import re\n",
        "from sklearn.utils import resample\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from seqeval.metrics import classification_report as seq_classification_report\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import random\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output"
      ],
      "metadata": {
        "id": "X9eoG7SZ5HSQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Memuat dataset dari file JSON\n",
        "with open('dataaa.json', 'r', encoding='utf-8') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Mengubah dataset menjadi DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Menentukan jumlah sampel maksimum per intent\n",
        "max_samples = 50\n",
        "\n",
        "df_list = []\n",
        "for intent in df['intent'].unique():\n",
        "    df_intent = df[df['intent'] == intent]\n",
        "    if len(df_intent) > max_samples:\n",
        "        df_intent = resample(df_intent, replace=False, n_samples=max_samples, random_state=42)\n",
        "    df_list.append(df_intent)\n",
        "\n",
        "df_balanced = pd.concat(df_list).reset_index(drop=True)\n",
        "\n",
        "# Periksa distribusi kelas\n",
        "class_counts = df_balanced['intent'].value_counts()\n",
        "print(\"Distribusi kelas sebelum penyesuaian:\")\n",
        "print(class_counts)\n",
        "\n",
        "# Gandakan sampel untuk kelas dengan hanya 1 sampel\n",
        "classes_with_one_sample = class_counts[class_counts == 1].index.tolist()\n",
        "for cls in classes_with_one_sample:\n",
        "    df_class = df_balanced[df_balanced['intent'] == cls]\n",
        "    df_balanced = pd.concat([df_balanced, df_class])  # Menggandakan sampel\n",
        "\n",
        "# Encode intents\n",
        "label_encoder = LabelEncoder()\n",
        "df_balanced['intent_label'] = label_encoder.fit_transform(df_balanced['intent'])\n",
        "\n",
        "# Simpan mapping label untuk penggunaan nanti\n",
        "intent_mapping = dict(zip(df_balanced['intent_label'], df_balanced['intent']))\n",
        "\n",
        "# Memfilter data yang memiliki entitas\n",
        "df_ner = df[df['entities'].map(lambda d: len(d)) > 0].reset_index(drop=True)\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    return text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JTcg4tL5Icx",
        "outputId": "5d4777c1-afc3-4cbe-bbdb-616d17041156"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribusi kelas sebelum penyesuaian:\n",
            "intent\n",
            "medical_inquiry_dog        50\n",
            "medical_inquiry_cat        50\n",
            "disease_prevention_cat     50\n",
            "general_conversation       50\n",
            "disease_prevention_dog     40\n",
            "science_conversation       40\n",
            "dog_healthcare             40\n",
            "filsafat                   40\n",
            "cat_healthcare             30\n",
            "pet_health_status_check    29\n",
            "intro_chat                 25\n",
            "pet_food_suggestion        23\n",
            "symptom_analysis_dog       20\n",
            "symptom_analysis_cat       20\n",
            "end_chat                   20\n",
            "pet_vaccination_check      20\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Periksa distribusi kelas\n",
        "class_counts = df_balanced['intent'].value_counts()\n",
        "print(\"Distribusi kelas sebelum penyesuaian:\")\n",
        "print(class_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8LdCA5K5bLM",
        "outputId": "79cedf70-92b5-41e7-c095-cbda4feaa18d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribusi kelas sebelum penyesuaian:\n",
            "intent\n",
            "medical_inquiry_dog        50\n",
            "medical_inquiry_cat        50\n",
            "disease_prevention_cat     50\n",
            "general_conversation       50\n",
            "disease_prevention_dog     40\n",
            "science_conversation       40\n",
            "dog_healthcare             40\n",
            "filsafat                   40\n",
            "cat_healthcare             30\n",
            "pet_health_status_check    29\n",
            "intro_chat                 25\n",
            "pet_food_suggestion        23\n",
            "symptom_analysis_dog       20\n",
            "symptom_analysis_cat       20\n",
            "end_chat                   20\n",
            "pet_vaccination_check      20\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Klasifikasi Intent\n",
        "texts = df_balanced['utterances'].apply(clean_text).tolist()\n",
        "labels = df_balanced['intent_label'].tolist()\n",
        "\n",
        "# Split the data\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    texts,\n",
        "    labels,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=labels\n",
        ")\n",
        "\n",
        "# Membuat tokenizer\n",
        "tokenizer = Tokenizer(oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(train_texts)\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(word_index) + 1\n",
        "\n",
        "# Mengonversi teks ke sequences\n",
        "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
        "val_sequences = tokenizer.texts_to_sequences(val_texts)\n",
        "\n",
        "# Padding sequences\n",
        "max_seq_length = max(max(len(seq) for seq in train_sequences), max(len(seq) for seq in val_sequences))\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_seq_length, padding='post')\n",
        "val_padded = pad_sequences(val_sequences, maxlen=max_seq_length, padding='post')\n",
        "\n",
        "# Mengonversi labels ke categorical\n",
        "num_classes = len(label_encoder.classes_)\n",
        "train_labels_cat = to_categorical(train_labels, num_classes=num_classes)\n",
        "val_labels_cat = to_categorical(val_labels, num_classes=num_classes)\n",
        "\n",
        "# NER\n",
        "def prepare_ner_data(df, tokenizer, max_seq_length):\n",
        "    texts = []\n",
        "    labels = []\n",
        "    for index, row in df.iterrows():\n",
        "        text = clean_text(row['utterances'])\n",
        "        entities = row['entities']\n",
        "        tokens = tokenizer.texts_to_sequences([text])[0]\n",
        "        label_seq = ['O'] * len(tokens)\n",
        "        for ent in entities:\n",
        "            ent_text = clean_text(ent['value'])\n",
        "            ent_tokens = tokenizer.texts_to_sequences([ent_text])[0]\n",
        "            for i in range(len(tokens)):\n",
        "                if tokens[i:i+len(ent_tokens)] == ent_tokens:\n",
        "                    label_seq[i] = 'B-' + ent['entity']\n",
        "                    for j in range(1, len(ent_tokens)):\n",
        "                        label_seq[i+j] = 'I-' + ent['entity']\n",
        "                    break\n",
        "        texts.append(tokens)\n",
        "        labels.append(label_seq)\n",
        "    # Padding\n",
        "    texts_padded = pad_sequences(texts, maxlen=max_seq_length, padding='post')\n",
        "    return texts_padded, labels\n",
        "\n",
        "# Membuat label encoder untuk NER\n",
        "all_labels = set()\n",
        "for label_list in df_ner['entities']:\n",
        "    for ent in label_list:\n",
        "        all_labels.add('B-' + ent['entity'])\n",
        "        all_labels.add('I-' + ent['entity'])\n",
        "all_labels.add('O')\n",
        "ner_label_encoder = {label: idx for idx, label in enumerate(sorted(all_labels))}\n",
        "ner_label_decoder = {idx: label for label, idx in ner_label_encoder.items()}\n",
        "\n",
        "# Siapkan data NER\n",
        "texts_ner = df_ner['utterances'].apply(clean_text).tolist()\n",
        "labels_ner = df_ner['entities'].tolist()\n",
        "\n",
        "texts_ner_prep, labels_ner_prep = prepare_ner_data(df_ner, tokenizer, max_seq_length)\n",
        "\n",
        "# Mengonversi labels ke format numerik\n",
        "def encode_ner_labels(labels, max_seq_length, ner_label_encoder):\n",
        "    labels_encoded = []\n",
        "    for label_seq in labels:\n",
        "        label_ids = [ner_label_encoder[label] for label in label_seq]\n",
        "        label_ids = label_ids + [ner_label_encoder['O']] * (max_seq_length - len(label_ids))\n",
        "        labels_encoded.append(label_ids)\n",
        "    labels_encoded = np.array(labels_encoded)\n",
        "    labels_encoded = to_categorical(labels_encoded, num_classes=len(ner_label_encoder))\n",
        "    return labels_encoded\n",
        "\n",
        "labels_ner_encoded = encode_ner_labels(labels_ner_prep, max_seq_length, ner_label_encoder)\n",
        "\n",
        "# Split the data\n",
        "train_texts_ner, val_texts_ner, train_labels_ner, val_labels_ner = train_test_split(\n",
        "    texts_ner_prep,\n",
        "    labels_ner_encoded,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "9b0Ka3qx5NZE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definisi Fungsi Attention\n",
        "from tensorflow.keras.layers import Layer\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "class AttentionLayer(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.W = self.add_weight(name='att_weight', shape=(input_shape[-1], 1),\n",
        "                                 initializer='glorot_uniform', trainable=True)\n",
        "        super(AttentionLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        e = K.tanh(K.dot(x, self.W))\n",
        "        a = K.softmax(e, axis=1)\n",
        "        output = x * a\n",
        "        return K.sum(output, axis=1)\n",
        "\n",
        "# Membangun Model\n",
        "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D, Embedding, Dense, Input, Bidirectional, LSTM, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Definisikan input\n",
        "inputs = Input(shape=(max_seq_length,))\n",
        "\n",
        "# Embedding Layer\n",
        "embedding = Embedding(input_dim=vocab_size, output_dim=256, input_length=max_seq_length)(inputs)\n",
        "\n",
        "# Convolutional Layer\n",
        "conv = Conv1D(filters=128, kernel_size=5, activation='relu')(embedding)\n",
        "conv = GlobalMaxPooling1D()(conv)\n",
        "\n",
        "# BiLSTM Layer dengan Attention\n",
        "lstm = Bidirectional(LSTM(128, return_sequences=True))(embedding)\n",
        "attention = AttentionLayer()(lstm)\n",
        "\n",
        "# Menggabungkan fitur dari CNN dan LSTM\n",
        "combined = tf.keras.layers.concatenate([conv, attention])\n",
        "\n",
        "# Fully Connected Layer\n",
        "dense = Dense(64, activation='relu')(combined)\n",
        "dropout = Dropout(0.5)(dense)\n",
        "outputs = Dense(num_classes, activation='softmax')(dropout)\n",
        "\n",
        "# Membangun Model\n",
        "model_intent = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Kompilasi Model\n",
        "model_intent.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Melatih Model\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
        "    ModelCheckpoint(\n",
        "        filepath='best_model_intent.weights.h5',\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True\n",
        "    )\n",
        "]\n",
        "\n",
        "history_intent = model_intent.fit(\n",
        "    train_padded,\n",
        "    train_labels_cat,\n",
        "    validation_data=(val_padded, val_labels_cat),\n",
        "    epochs=20,\n",
        "    batch_size=16,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9yiHA945cT2",
        "outputId": "bf7165b9-07fa-4009-b740-3667e2fc0d1b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 95ms/step - accuracy: 0.0999 - loss: 2.7420 - val_accuracy: 0.2909 - val_loss: 2.4055\n",
            "Epoch 2/20\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.2824 - loss: 2.2833 - val_accuracy: 0.3273 - val_loss: 1.8848\n",
            "Epoch 3/20\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.3266 - loss: 1.8811 - val_accuracy: 0.4909 - val_loss: 1.4280\n",
            "Epoch 4/20\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.4702 - loss: 1.4924 - val_accuracy: 0.7000 - val_loss: 1.1239\n",
            "Epoch 5/20\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step - accuracy: 0.6390 - loss: 1.0742 - val_accuracy: 0.7545 - val_loss: 0.8491\n",
            "Epoch 6/20\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.7401 - loss: 0.8220 - val_accuracy: 0.7636 - val_loss: 0.6357\n",
            "Epoch 7/20\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.7861 - loss: 0.6990 - val_accuracy: 0.8545 - val_loss: 0.5048\n",
            "Epoch 8/20\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.8590 - loss: 0.4973 - val_accuracy: 0.9000 - val_loss: 0.3919\n",
            "Epoch 9/20\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - accuracy: 0.8996 - loss: 0.3502 - val_accuracy: 0.9091 - val_loss: 0.3855\n",
            "Epoch 10/20\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.9100 - loss: 0.2942 - val_accuracy: 0.9182 - val_loss: 0.3367\n",
            "Epoch 11/20\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.9101 - loss: 0.2734 - val_accuracy: 0.9455 - val_loss: 0.2597\n",
            "Epoch 12/20\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.9459 - loss: 0.1687 - val_accuracy: 0.9364 - val_loss: 0.2376\n",
            "Epoch 13/20\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.9646 - loss: 0.1665 - val_accuracy: 0.9545 - val_loss: 0.2335\n",
            "Epoch 14/20\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 132ms/step - accuracy: 0.9848 - loss: 0.1030 - val_accuracy: 0.9273 - val_loss: 0.2337\n",
            "Epoch 15/20\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - accuracy: 0.9693 - loss: 0.1052 - val_accuracy: 0.9545 - val_loss: 0.1946\n",
            "Epoch 16/20\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.9866 - loss: 0.0809 - val_accuracy: 0.9545 - val_loss: 0.2159\n",
            "Epoch 17/20\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - accuracy: 0.9847 - loss: 0.0782 - val_accuracy: 0.9273 - val_loss: 0.2969\n",
            "Epoch 18/20\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 93ms/step - accuracy: 0.9759 - loss: 0.0935 - val_accuracy: 0.9455 - val_loss: 0.2484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definisi Fungsi Attention\n",
        "from tensorflow.keras.layers import TimeDistributed\n",
        "\n",
        "class TimeDistributedAttention(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(TimeDistributedAttention, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.W = self.add_weight(name='att_weight', shape=(input_shape[-1], input_shape[-1]),\n",
        "                                 initializer='glorot_uniform', trainable=True)\n",
        "        self.b = self.add_weight(name='att_bias', shape=(input_shape[-1],),\n",
        "                                 initializer='zeros', trainable=True)\n",
        "        super(TimeDistributedAttention, self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        e = K.tanh(K.dot(x, self.W) + self.b)\n",
        "        a = K.softmax(e, axis=1)\n",
        "        output = x * a\n",
        "        return output\n",
        "\n",
        "# Membangun Model\n",
        "from tensorflow.keras.layers import TimeDistributed, Bidirectional, Dense, LSTM, Embedding, Dropout\n",
        "\n",
        "# Definisikan input\n",
        "inputs = Input(shape=(max_seq_length,))\n",
        "\n",
        "# Embedding Layer\n",
        "embedding = Embedding(input_dim=vocab_size, output_dim=256, input_length=max_seq_length)(inputs)\n",
        "\n",
        "# BiLSTM Layer dengan Attention\n",
        "lstm = Bidirectional(LSTM(128, return_sequences=True))(embedding)\n",
        "attention = TimeDistributedAttention()(lstm)\n",
        "\n",
        "# TimeDistributed Dense Layer\n",
        "outputs = TimeDistributed(Dense(len(ner_label_encoder), activation='softmax'))(attention)\n",
        "\n",
        "# Membangun Model\n",
        "model_ner = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Kompilasi Model\n",
        "model_ner.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Melatih Model\n",
        "callbacks_ner = [\n",
        "    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
        "    ModelCheckpoint(\n",
        "        filepath='best_model_ner.weights.h5',\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True\n",
        "    )\n",
        "]\n",
        "\n",
        "history_ner = model_ner.fit(\n",
        "    train_texts_ner,\n",
        "    train_labels_ner,\n",
        "    validation_data=(val_texts_ner, val_labels_ner),\n",
        "    epochs=20,\n",
        "    batch_size=16,\n",
        "    callbacks=callbacks_ner\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjMKQzlo5geF",
        "outputId": "3b58d17c-0263-4661-cf26-c5fc6f55faa6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 193ms/step - accuracy: 0.6434 - loss: 2.7673 - val_accuracy: 0.8119 - val_loss: 2.2260\n",
            "Epoch 2/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - accuracy: 0.7957 - loss: 2.0597 - val_accuracy: 0.8119 - val_loss: 1.6159\n",
            "Epoch 3/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.7947 - loss: 1.5659 - val_accuracy: 0.8119 - val_loss: 1.3061\n",
            "Epoch 4/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.7936 - loss: 1.2978 - val_accuracy: 0.8119 - val_loss: 1.1014\n",
            "Epoch 5/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.8068 - loss: 1.0960 - val_accuracy: 0.8119 - val_loss: 0.9502\n",
            "Epoch 6/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.8089 - loss: 0.9493 - val_accuracy: 0.8119 - val_loss: 0.8420\n",
            "Epoch 7/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.8120 - loss: 0.8416 - val_accuracy: 0.8119 - val_loss: 0.7615\n",
            "Epoch 8/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - accuracy: 0.8043 - loss: 0.7751 - val_accuracy: 0.8119 - val_loss: 0.7017\n",
            "Epoch 9/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 105ms/step - accuracy: 0.7987 - loss: 0.7273 - val_accuracy: 0.8119 - val_loss: 0.6580\n",
            "Epoch 10/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.7927 - loss: 0.6788 - val_accuracy: 0.8136 - val_loss: 0.6220\n",
            "Epoch 11/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.8121 - loss: 0.6224 - val_accuracy: 0.8438 - val_loss: 0.5930\n",
            "Epoch 12/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.8229 - loss: 0.6085 - val_accuracy: 0.8456 - val_loss: 0.5723\n",
            "Epoch 13/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.8452 - loss: 0.5535 - val_accuracy: 0.8456 - val_loss: 0.5519\n",
            "Epoch 14/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.8231 - loss: 0.5549 - val_accuracy: 0.8438 - val_loss: 0.5295\n",
            "Epoch 15/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.8188 - loss: 0.5354 - val_accuracy: 0.8438 - val_loss: 0.5137\n",
            "Epoch 16/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.8327 - loss: 0.5004 - val_accuracy: 0.8430 - val_loss: 0.4970\n",
            "Epoch 17/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 125ms/step - accuracy: 0.8339 - loss: 0.4723 - val_accuracy: 0.8430 - val_loss: 0.4858\n",
            "Epoch 18/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 130ms/step - accuracy: 0.8264 - loss: 0.4722 - val_accuracy: 0.8421 - val_loss: 0.4772\n",
            "Epoch 19/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.8530 - loss: 0.4367 - val_accuracy: 0.8611 - val_loss: 0.4615\n",
            "Epoch 20/20\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.8482 - loss: 0.4439 - val_accuracy: 0.8645 - val_loss: 0.4621\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load best weights\n",
        "model_intent.load_weights('best_model_intent.weights.h5')\n",
        "\n",
        "# Evaluasi\n",
        "loss, accuracy = model_intent.evaluate(val_padded, val_labels_cat)\n",
        "print(f'Akurasi Model Klasifikasi Intent: {accuracy * 100:.2f}%')\n",
        "\n",
        "# Predict on validation data\n",
        "val_preds = model_intent.predict(val_padded)\n",
        "val_preds = np.argmax(val_preds, axis=1)\n",
        "val_true = np.argmax(val_labels_cat, axis=1)\n",
        "\n",
        "# Get unique labels present in val_true\n",
        "unique_labels = np.unique(val_true)\n",
        "\n",
        "# Filter label_encoder.classes_ to include only the present labels\n",
        "target_names = [label_encoder.classes_[i] for i in unique_labels]\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(val_true, val_preds, labels=unique_labels, target_names=target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kK80vJbd56Zd",
        "outputId": "c9906465-bcea-4065-951a-028a20523771"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9641 - loss: 0.1692\n",
            "Akurasi Model Klasifikasi Intent: 95.45%\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144ms/step\n",
            "                         precision    recall  f1-score   support\n",
            "\n",
            "         cat_healthcare       0.86      1.00      0.92         6\n",
            " disease_prevention_cat       1.00      1.00      1.00        10\n",
            " disease_prevention_dog       1.00      1.00      1.00         8\n",
            "         dog_healthcare       1.00      1.00      1.00         8\n",
            "               end_chat       1.00      1.00      1.00         4\n",
            "               filsafat       1.00      1.00      1.00         8\n",
            "   general_conversation       1.00      0.90      0.95        10\n",
            "             intro_chat       0.62      1.00      0.77         5\n",
            "    medical_inquiry_cat       1.00      1.00      1.00        10\n",
            "    medical_inquiry_dog       1.00      1.00      1.00        10\n",
            "    pet_food_suggestion       1.00      1.00      1.00         5\n",
            "pet_health_status_check       1.00      1.00      1.00         6\n",
            "  pet_vaccination_check       1.00      0.75      0.86         4\n",
            "   science_conversation       0.83      0.62      0.71         8\n",
            "   symptom_analysis_cat       1.00      1.00      1.00         4\n",
            "   symptom_analysis_dog       1.00      1.00      1.00         4\n",
            "\n",
            "               accuracy                           0.95       110\n",
            "              macro avg       0.96      0.95      0.95       110\n",
            "           weighted avg       0.96      0.95      0.95       110\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load best weights\n",
        "model_ner.load_weights('best_model_ner.weights.h5')\n",
        "\n",
        "# Evaluasi\n",
        "loss, accuracy = model_ner.evaluate(val_texts_ner, val_labels_ner)\n",
        "print(f'Akurasi Model NER: {accuracy * 100:.2f}%')\n",
        "\n",
        "# Predict on validation data\n",
        "val_preds = model_ner.predict(val_texts_ner)\n",
        "val_preds = np.argmax(val_preds, axis=-1)\n",
        "val_true = np.argmax(val_labels_ner, axis=-1)\n",
        "\n",
        "# Konversi label ke format aslinya\n",
        "true_labels = []\n",
        "pred_labels = []\n",
        "\n",
        "for i in range(len(val_preds)):\n",
        "    true_label = []\n",
        "    pred_label = []\n",
        "    for j in range(len(val_preds[i])):\n",
        "        true_l = ner_label_decoder[val_true[i][j]]\n",
        "        pred_l = ner_label_decoder[val_preds[i][j]]\n",
        "        if true_l != 'O':\n",
        "            true_label.append(true_l)\n",
        "            pred_label.append(pred_l)\n",
        "    true_labels.append(true_label)\n",
        "    pred_labels.append(pred_label)\n",
        "\n",
        "# Classification report\n",
        "print(seq_classification_report(true_labels, pred_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwbqW9Q76dFV",
        "outputId": "2fb09e49-923a-4e50-9fe3-5cbceb94b1a9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8630 - loss: 0.4660\n",
            "Akurasi Model NER: 86.11%\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      animal       1.00      0.83      0.91        48\n",
            "   condition       0.00      0.00      0.00         1\n",
            "     disease       0.00      0.00      0.00        13\n",
            "    duration       0.00      0.00      0.00         2\n",
            "        food       0.00      0.00      0.00         2\n",
            "     symptom       0.08      0.04      0.05        47\n",
            "     vaccine       0.00      0.00      0.00         1\n",
            "\n",
            "   micro avg       0.64      0.37      0.47       114\n",
            "   macro avg       0.15      0.13      0.14       114\n",
            "weighted avg       0.45      0.37      0.41       114\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simpan model dan tokenizer\n",
        "model_intent.save('model_intent.h5')\n",
        "model_ner.save('model_ner.h5')\n",
        "\n",
        "import pickle\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('label_encoder.pickle', 'wb') as handle:\n",
        "    pickle.dump(label_encoder, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('ner_label_encoder.pickle', 'wb') as handle:\n",
        "    pickle.dump(ner_label_encoder, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# Memuat model dan tokenizer\n",
        "from tensorflow.keras.models import load_model\n",
        "model_intent = load_model('model_intent.h5', custom_objects={'AttentionLayer': AttentionLayer})\n",
        "model_ner = load_model('model_ner.h5', custom_objects={'TimeDistributedAttention': TimeDistributedAttention})\n",
        "\n",
        "import pickle\n",
        "with open('tokenizer.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)\n",
        "with open('label_encoder.pickle', 'rb') as handle:\n",
        "    label_encoder = pickle.load(handle)\n",
        "with open('ner_label_encoder.pickle', 'rb') as handle:\n",
        "    ner_label_encoder = pickle.load(handle)\n",
        "ner_label_decoder = {idx: label for label, idx in ner_label_encoder.items()}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtWTjDl26nOV",
        "outputId": "55720fb8-858b-4d64-e175-d2fdf4b70ed4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_intent(text):\n",
        "    text_clean = clean_text(text)\n",
        "    seq = tokenizer.texts_to_sequences([text_clean])\n",
        "    padded_seq = pad_sequences(seq, maxlen=max_seq_length, padding='post')\n",
        "    pred = model_intent.predict(padded_seq)\n",
        "    predicted_label = np.argmax(pred, axis=1)[0]\n",
        "    intent = label_encoder.inverse_transform([predicted_label])[0]\n",
        "    return intent\n",
        "\n",
        "def predict_entities(text):\n",
        "    text_clean = clean_text(text)\n",
        "    seq = tokenizer.texts_to_sequences([text_clean])\n",
        "    padded_seq = pad_sequences(seq, maxlen=max_seq_length, padding='post')\n",
        "    pred = model_ner.predict(padded_seq)\n",
        "    pred_labels = np.argmax(pred, axis=-1)[0]\n",
        "    tokens = tokenizer.sequences_to_texts(seq)[0].split()\n",
        "    entities = []\n",
        "    for idx, label_id in enumerate(pred_labels[:len(tokens)]):\n",
        "        label = ner_label_decoder[label_id]\n",
        "        if label != 'O':\n",
        "            entities.append({'entity': label.split('-')[1], 'value': tokens[idx]})\n",
        "    return entities"
      ],
      "metadata": {
        "id": "Gg0q8LGn6sRZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pastikan model telah dipanggil\n",
        "_ = model_intent.predict(train_padded[:1])\n",
        "\n",
        "# Mendefinisikan model tanpa layer output untuk mendapatkan embedding\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "embedding_model = Model(inputs=model_intent.input, outputs=model_intent.get_layer('dense').output)\n",
        "\n",
        "# Mendapatkan embedding dari dataset\n",
        "utterance_embeddings = embedding_model.predict(train_padded)\n",
        "\n",
        "# Fungsi get_response\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def get_response(user_input):\n",
        "    # Preprocess input\n",
        "    text_clean = clean_text(user_input)\n",
        "    seq = tokenizer.texts_to_sequences([text_clean])\n",
        "    padded_seq = pad_sequences(seq, maxlen=max_seq_length, padding='post')\n",
        "\n",
        "    # Mendapatkan embedding input pengguna\n",
        "    user_embedding = embedding_model.predict(padded_seq)\n",
        "\n",
        "    # Menghitung kemiripan\n",
        "    similarities = cosine_similarity(user_embedding, utterance_embeddings)\n",
        "\n",
        "    # Dapatkan indeks dengan similarity tertinggi\n",
        "    most_similar_idx = np.argmax(similarities[0])\n",
        "\n",
        "    # Jika similarity rendah, berikan respon default\n",
        "    if similarities[0][most_similar_idx] < 0.5:\n",
        "        return \"Maaf, saya tidak memahami pertanyaan Anda.\"\n",
        "\n",
        "    # Ambil respon yang sesuai\n",
        "    response = df_balanced.iloc[most_similar_idx]['responses']\n",
        "\n",
        "    return response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0lsBKZ_6viK",
        "outputId": "09a70f9c-6cd7-45bf-de5e-bff73aa92068"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7867e93a24d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "\n",
        "def google_search(query):\n",
        "    service = build(\"customsearch\", \"v1\", developerKey=\"AIzaSyD-f-0S98J0bcdG_5AvbuNGSBVHIgQIX1Y\")\n",
        "    res = service.cse().list(q=query, cx='30b6a924536894083').execute()\n",
        "    results = res.get('items', [])\n",
        "    if results:\n",
        "        snippet = results[0]['snippet']\n",
        "        return snippet\n",
        "    else:\n",
        "        return \"Maaf, saya tidak menemukan informasi yang Anda cari.\""
      ],
      "metadata": {
        "id": "lbJBuVc97mQg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot_response(user_input):\n",
        "    # Prediksi intent dan entitas\n",
        "    intent = predict_intent(user_input)\n",
        "    entities = predict_entities(user_input)\n",
        "\n",
        "    # Jika intent tidak dikenali, gunakan Google Search\n",
        "    if intent == 'general_conversation':\n",
        "        response = get_response(user_input)\n",
        "    else:\n",
        "        # Gunakan Google Search untuk mendapatkan informasi tambahan\n",
        "        query = user_input\n",
        "        search_result = google_search(query)\n",
        "        response = f\"{get_response(user_input)}\\n\\nInformasi tambahan:\\n{search_result}\"\n",
        "\n",
        "    return response\n",
        "\n",
        "# Membuat widget input dan output\n",
        "input_box = widgets.Text(\n",
        "    value='',\n",
        "    placeholder='Ketik pesan Anda...',\n",
        "    description='Anda:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "output_area = widgets.Output()\n",
        "\n",
        "def on_submit(sender):\n",
        "    user_input = input_box.value\n",
        "    input_box.value = ''\n",
        "    response = chatbot_response(user_input)\n",
        "    with output_area:\n",
        "        print(f\"Anda: {user_input}\")\n",
        "        print(f\"Chatbot: {response}\\n\")\n",
        "\n",
        "input_box.on_submit(on_submit)\n",
        "\n",
        "display(input_box, output_area)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50,
          "referenced_widgets": [
            "d2e0db013ee24a1ca7c7b2818732afa2",
            "932d1e9f7e4944b2972acc0926f9e7e7",
            "3963618285d54ca0b0375c7e4f6b3175",
            "b7797962f35948f7ae1ca4ed5ffebb85",
            "bfbb887014e64ad9b11cd4e3d4ad352f"
          ]
        },
        "id": "9tSXLpbZ6yAV",
        "outputId": "79d0f647-ca62-4ba1-878a-54beb1e47ce2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Text(value='', description='Anda:', placeholder='Ketik pesan Anda...')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2e0db013ee24a1ca7c7b2818732afa2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b7797962f35948f7ae1ca4ed5ffebb85"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Contoh kalimat\n",
        "test_sentence = \"Kucing saya terlihat sering muntah dan tidak mau makan. Apa yang harus saya lakukan\"\n",
        "\n",
        "# Prediksi intent\n",
        "predicted_intent = predict_intent(test_sentence)\n",
        "print(f\"Intent yang diprediksi: {predicted_intent}\")\n",
        "\n",
        "# Prediksi entitas\n",
        "predicted_entities = predict_entities(test_sentence)\n",
        "print(\"Entitas yang ditemukan:\")\n",
        "for entity in predicted_entities:\n",
        "    print(f\"- {entity['entity']}: {entity['value']}\")\n",
        "\n",
        "# Mendapatkan respon\n",
        "response = chatbot_response(test_sentence)\n",
        "print(f\"Chatbot: {response}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Ju9PCLo7KsW",
        "outputId": "e7306e03-b401-4e71-b23e-3194dd44e599"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
            "Intent yang diprediksi: medical_inquiry_cat\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
            "Entitas yang ditemukan:\n",
            "- animal: kucing\n",
            "- symptom: sering\n",
            "- symptom: muntah\n",
            "- symptom: mau\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n",
            "Chatbot: Saya tidak menonton film, tetapi saya tahu banyak orang suka film seperti 'Interstellar' atau 'Inception'. Bagaimana dengan Anda?\n",
            "\n",
            "Informasi tambahan:\n",
            "Menjaga kesehatan kucing juga bisa dilakukan dengan memberi makanan terbaik. Sekarang, kamu bisa belanja makanan sehat untuk kucing peliharaan melalui ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B4LMgNwQ7Nlr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}