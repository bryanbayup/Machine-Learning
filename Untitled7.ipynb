{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM9AFlsN5Dw46svdqg/mVci",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bryanbayup/Machine-Learning/blob/main/Untitled7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Sastrawi\n",
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ojn36Qg4tDGH",
        "outputId": "fe22bb6d-7a7c-4f68-c3f4-c0387d5aab6b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Sastrawi\n",
            "  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl.metadata (909 bytes)\n",
            "Downloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.7/209.7 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Sastrawi\n",
            "Successfully installed Sastrawi-1.0.1\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.5)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qtRMrEFxs1ab"
      },
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "import json\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout, Bidirectional, LSTM, Conv1D, GlobalMaxPooling1D, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "from gensim.models import KeyedVectors\n",
        "import re\n",
        "import os\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Download FastText\n",
        "!wget -O id.tar.gz \"https://www.dropbox.com/scl/fi/sju4o3keikox69euw51vy/id.tar.gz?rlkey=5jr3ijtbdwfahq7xcgig28qvy&e=1&st=gntzkzeo&dl=1\"\n",
        "!tar -xzf id.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1wvSeIFtNg1",
        "outputId": "7453edf3-6566-4f82-8363-8f16b16b5d2b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-12-02 14:11:31--  https://www.dropbox.com/scl/fi/sju4o3keikox69euw51vy/id.tar.gz?rlkey=5jr3ijtbdwfahq7xcgig28qvy&e=1&st=gntzkzeo&dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc3e9de2d8c78ba56429d0ccf7bb.dl.dropboxusercontent.com/cd/0/inline/Cfc-n03DTvA-tvGxdfuaBtx1FYn7WID4H4MbpqWMF0X_a0c-hvnwvNmnN7VewMOqTLzBji9jKKCwZvNfEbrUl6SaHhZxrznLPxuI0rCu8WfSW4Dx0D-V7JtJKQGcPkdU16w/file?dl=1# [following]\n",
            "--2024-12-02 14:11:32--  https://uc3e9de2d8c78ba56429d0ccf7bb.dl.dropboxusercontent.com/cd/0/inline/Cfc-n03DTvA-tvGxdfuaBtx1FYn7WID4H4MbpqWMF0X_a0c-hvnwvNmnN7VewMOqTLzBji9jKKCwZvNfEbrUl6SaHhZxrznLPxuI0rCu8WfSW4Dx0D-V7JtJKQGcPkdU16w/file?dl=1\n",
            "Resolving uc3e9de2d8c78ba56429d0ccf7bb.dl.dropboxusercontent.com (uc3e9de2d8c78ba56429d0ccf7bb.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n",
            "Connecting to uc3e9de2d8c78ba56429d0ccf7bb.dl.dropboxusercontent.com (uc3e9de2d8c78ba56429d0ccf7bb.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/CfcQNGkkHxPERGv68BgRkBSmhCaExqlF1HdBISZ-7TuPLgsqe-xeHVFejUV3_fKxOdy7IlwhJUAl3nXujk4-fAxPo1me3IV-N76yqjeGk4t06EjwQq8t_4bAbsr6bxv7Hpx13zlgBUtKexbTx-1QA9N-vxNAjCq6M6k8BAUfeJAJhRDnL8Rg7QEqBbrZgjhEkDFYjp7t5lMRUGExa0XIYzv26lvIkJO--JgzSGpXu9ihfCJW3nRJ-w1Y_x59c1jtR9BVb5Lz2odALXGOqN5rqc-55DsO9aP9JCSF91kDy9V8RqvRyk65LETqNIqNmef4RVLjAG0QSmEvn9xye_-TV678TEDT2HQXv3JbcI6Upn7Wsg/file?dl=1 [following]\n",
            "--2024-12-02 14:11:33--  https://uc3e9de2d8c78ba56429d0ccf7bb.dl.dropboxusercontent.com/cd/0/inline2/CfcQNGkkHxPERGv68BgRkBSmhCaExqlF1HdBISZ-7TuPLgsqe-xeHVFejUV3_fKxOdy7IlwhJUAl3nXujk4-fAxPo1me3IV-N76yqjeGk4t06EjwQq8t_4bAbsr6bxv7Hpx13zlgBUtKexbTx-1QA9N-vxNAjCq6M6k8BAUfeJAJhRDnL8Rg7QEqBbrZgjhEkDFYjp7t5lMRUGExa0XIYzv26lvIkJO--JgzSGpXu9ihfCJW3nRJ-w1Y_x59c1jtR9BVb5Lz2odALXGOqN5rqc-55DsO9aP9JCSF91kDy9V8RqvRyk65LETqNIqNmef4RVLjAG0QSmEvn9xye_-TV678TEDT2HQXv3JbcI6Upn7Wsg/file?dl=1\n",
            "Reusing existing connection to uc3e9de2d8c78ba56429d0ccf7bb.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2333351997 (2.2G) [application/binary]\n",
            "Saving to: ‘id.tar.gz’\n",
            "\n",
            "id.tar.gz           100%[===================>]   2.17G  53.5MB/s    in 41s     \n",
            "\n",
            "2024-12-02 14:12:15 (53.9 MB/s) - ‘id.tar.gz’ saved [2333351997/2333351997]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load FastText Embedding\n",
        "fasttext_model = KeyedVectors.load_word2vec_format('id.vec', binary=False)\n",
        "\n",
        "# 2. Load Dataset\n",
        "with open('data.json', 'r', encoding='utf-8') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# 3. Preprocessing\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    return text\n",
        "\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = clean_text(text)\n",
        "    tokens = text.split()\n",
        "    tokens = [stemmer.stem(token) for token in tokens]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "utterances = []\n",
        "intents = []\n",
        "entities = []\n",
        "\n",
        "for conversation in data:\n",
        "    for turn in conversation:\n",
        "        if turn['speaker'] == 'user':\n",
        "            utterances.append(preprocess_text(turn['utterance']))\n",
        "            intents.append(turn.get('intent', 'unknown'))\n",
        "            entities.append(turn.get('entities', []))\n",
        "\n",
        "# 4. Tokenization and Padding\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(utterances)\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(utterances)\n",
        "max_seq_length = max(len(seq) for seq in sequences)\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_seq_length, padding='post')\n",
        "\n",
        "# 5. Prepare Intent Labels\n",
        "unique_intents = sorted(set(intents))\n",
        "intent_to_idx = {intent: idx for idx, intent in enumerate(unique_intents)}\n",
        "intent_labels = [intent_to_idx[intent] for intent in intents]\n",
        "intent_labels_cat = to_categorical(intent_labels, num_classes=len(unique_intents))\n",
        "\n",
        "# 6. Create Embedding Matrix\n",
        "embedding_dim = fasttext_model.vector_size\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, idx in tokenizer.word_index.items():\n",
        "    if word in fasttext_model:\n",
        "        embedding_matrix[idx] = fasttext_model[word]\n",
        "\n",
        "# 7. Split Data for Intent Classification\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    padded_sequences, intent_labels_cat, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "kBFxCjaps6X0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Build Intent Classification Model\n",
        "def build_intent_model():\n",
        "    inputs = Input(shape=(max_seq_length,))\n",
        "    embedding = tf.keras.layers.Embedding(\n",
        "        input_dim=vocab_size,\n",
        "        output_dim=embedding_dim,\n",
        "        weights=[embedding_matrix],\n",
        "        input_length=max_seq_length,\n",
        "        trainable=False\n",
        "    )(inputs)\n",
        "    conv = Conv1D(filters=128, kernel_size=3, activation='relu')(embedding)\n",
        "    global_pool = GlobalMaxPooling1D()(conv)\n",
        "    dense = Dense(64, activation='relu')(global_pool)\n",
        "    dropout = Dropout(0.5)(dense)\n",
        "    outputs = Dense(len(unique_intents), activation='softmax')(dropout)\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "model_intent = build_intent_model()\n",
        "model_intent.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgeiaNWft9HD",
        "outputId": "da406471-a427-400d-f143-5c3a97f7b45f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Train Intent Classification Model\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "model_intent.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=20, batch_size=16,\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1fKqCfTuFAd",
        "outputId": "eef9f4e3-5809-4a3e-e0a5-b0c94b1679e4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/losses/losses.py:27: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
            "  return self.fn(y_true, y_pred, **self._fn_kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 2/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 3/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
            "Epoch 4/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ca02742fee0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Prepare Data for NER\n",
        "def prepare_ner_data(entities, tokenizer, max_seq_length):\n",
        "    texts = []\n",
        "    labels = []\n",
        "    all_labels = set()\n",
        "\n",
        "    # Buat label encoder untuk semua label NER\n",
        "    for entity_list in entities:\n",
        "        for entity in entity_list:\n",
        "            all_labels.add(f\"B-{entity['entity']}\")\n",
        "            all_labels.add(f\"I-{entity['entity']}\")\n",
        "    all_labels.add(\"O\")\n",
        "    ner_label_encoder = {label: idx for idx, label in enumerate(sorted(all_labels))}\n",
        "    ner_label_decoder = {idx: label for label, idx in ner_label_encoder.items()}\n",
        "\n",
        "    # Iterasi setiap utterance\n",
        "    for i, utterance in enumerate(utterances):\n",
        "        tokens = tokenizer.texts_to_sequences([utterance])[0]\n",
        "        tokenized_text = tokenizer.sequences_to_texts([tokens])[0].split()  # Token berdasarkan tokenizer\n",
        "        label_seq = [\"O\"] * len(tokenized_text)\n",
        "\n",
        "        for entity in entities[i]:\n",
        "            entity_text = preprocess_text(entity['value'])\n",
        "            entity_tokens = tokenizer.texts_to_sequences([entity_text])[0]\n",
        "            entity_len = len(entity_tokens)\n",
        "\n",
        "            # Cari kecocokan entitas dalam teks tokenized\n",
        "            for idx in range(len(tokenized_text) - entity_len + 1):\n",
        "                if tokens[idx:idx + entity_len] == entity_tokens:\n",
        "                    label_seq[idx] = f\"B-{entity['entity']}\"\n",
        "                    for j in range(1, entity_len):\n",
        "                        label_seq[idx + j] = f\"I-{entity['entity']}\"\n",
        "                    break\n",
        "\n",
        "        # Tambahkan ke dataset\n",
        "        texts.append(tokens)\n",
        "        labels.append([ner_label_encoder[label] for label in label_seq])\n",
        "\n",
        "    # Padding sequences\n",
        "    texts_padded = pad_sequences(texts, maxlen=max_seq_length, padding='post')\n",
        "    labels_padded = pad_sequences(labels, maxlen=max_seq_length, padding='post')\n",
        "    labels_cat = to_categorical(labels_padded, num_classes=len(ner_label_encoder))\n",
        "\n",
        "    return texts_padded, labels_cat, ner_label_encoder, ner_label_decoder\n",
        "\n",
        "X_ner, y_ner, ner_label_encoder, ner_label_decoder = prepare_ner_data(entities, tokenizer, max_seq_length)\n",
        "\n",
        "X_train_ner, X_val_ner, y_train_ner, y_val_ner = train_test_split(\n",
        "    X_ner, y_ner, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "-pux94PauN3-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 11. Build NER Model\n",
        "def build_ner_model():\n",
        "    inputs = Input(shape=(max_seq_length,))\n",
        "    embedding = tf.keras.layers.Embedding(\n",
        "        input_dim=vocab_size,\n",
        "        output_dim=embedding_dim,\n",
        "        weights=[embedding_matrix],\n",
        "        input_length=max_seq_length,\n",
        "        trainable=False\n",
        "    )(inputs)\n",
        "    lstm = Bidirectional(LSTM(64, return_sequences=True))(embedding)\n",
        "    dropout = Dropout(0.5)(lstm)\n",
        "    outputs = TimeDistributed(Dense(len(ner_label_encoder), activation='softmax'))(dropout)\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "model_ner = build_ner_model()\n",
        "model_ner.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 12. Train NER Model\n",
        "model_ner.fit(\n",
        "    X_train_ner, y_train_ner,\n",
        "    validation_data=(X_val_ner, y_val_ner),\n",
        "    epochs=20, batch_size=16,\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-rgVZcLuTmN",
        "outputId": "a2919af5-32c8-4dda-91ce-2269fa4a8ed4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.4226 - loss: 2.1344 - val_accuracy: 0.8494 - val_loss: 1.1819\n",
            "Epoch 2/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8089 - loss: 1.1045 - val_accuracy: 0.8222 - val_loss: 0.7242\n",
            "Epoch 3/20\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.8093 - loss: 0.7690 - val_accuracy: 0.8691 - val_loss: 0.5488\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ca01f4d10c0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GINc2HFOvCXm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}