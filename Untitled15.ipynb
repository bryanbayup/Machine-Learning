{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNncPRPSnjSX4DRNK7MDK63",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ddce7e299bd04ffeb116b31c1378757f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Anda:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_e32daa61bdbf46c4b414021bacb734b3",
            "placeholder": "Ketik pesan Anda...",
            "style": "IPY_MODEL_4dd6e7a0dca74d5f819bc01152a0fd87",
            "value": ""
          }
        },
        "e32daa61bdbf46c4b414021bacb734b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4dd6e7a0dca74d5f819bc01152a0fd87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2136a2d2d7d435781e8a6045665bd09": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_80e6b317d8e144f687cadafa4d776248",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Anda: # Membuat widget input dan output input_box = widgets.Text(     value='',     placeholder='Ketik pesan Anda...',     description='Anda:',     disabled=False )  output_area = widgets.Output()  def on_submit(sender):     user_input = input_box.value     input_box.value = ''     response = chatbot_response(user_input)     with output_area:         print(f\"Anda: {user_input}\")         print(f\"Chatbot: {response}\\n\")  input_box.on_submit(on_submit)  display(input_box, output_area)\n",
                  "Chatbot: Melihat Anda senang dan mendapatkan bantuan dari saya adalah hal yang membuat saya 'bahagia' sebagai chatbot!\n",
                  "\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Anda: Kucing saya kehilangan nafsu makan selama seminggu terakhir. Apa yang salah\n",
                  "Chatbot: Kehilangan nafsu makan bisa disebabkan oleh stres, demam, atau gangguan pencernaan. Periksakan ke dokter hewan untuk diagnosis lebih lanjut.\n",
                  "\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Anda: Bagaimana saya bisa menjadi versi terbaik dari diri saya\n",
                  "Chatbot: Berikan porsi makan yang sesuai, pilih makanan berkualitas, dan pastikan anjing mendapatkan olahraga teratur untuk menjaga berat badan ideal.\n",
                  "\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Anda: Bagaimana cara mencegah kucing saya terkena penyakit jantung\n",
                  "Chatbot: Untuk mencegah penyakit jantung pada kucing, berikan makanan berkualitas yang mendukung kesehatan jantung dan lakukan pemeriksaan kesehatan rutin. Hindari obesitas pada kucing.\n",
                  "\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Anda: Apa kabar malam ini\n",
                  "Chatbot: Saya baik-baik saja, terima kasih! Bagaimana dengan Anda?\n",
                  "\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Anda: Bagaimana cuaca hari ini\n",
                  "Chatbot: Saya baik-baik saja, terima kasih! Bagaimana dengan Anda?\n",
                  "\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Anda: Apa itu gaya elektromagnetik\n",
                  "Chatbot: Gaya elektromagnetik adalah salah satu dari empat gaya dasar alam semesta yang mengatur interaksi antara partikel bermuatan listrik.\n",
                  "\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Anda: Bagaimana cara kerja panel surya\n",
                  "Chatbot: Panel surya mengubah energi cahaya menjadi listrik menggunakan sel fotovoltaik yang terbuat dari bahan semikonduktor seperti silikon.\n",
                  "\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Anda: anjing saya tidak sakit\n",
                  "Chatbot: Tanda-tandanya meliputi perubahan nafsu makan, lesu, muntah, diare, batuk, atau perilaku yang tidak biasa. Periksakan ke dokter hewan jika gejalanya berlanjut.\n",
                  "\n"
                ]
              }
            ]
          }
        },
        "80e6b317d8e144f687cadafa4d776248": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bryanbayup/Machine-Learning/blob/main/Untitled15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seqeval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZQPooANmiDr",
        "outputId": "5be93da3-9f92-4986-b1d6-8a43d2a75ca4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.5.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.5.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=31291aad39b2dd7138bb96742a1c7f94fe27d0060d5c9baed04b289b062c5f56\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import re\n",
        "from sklearn.utils import resample\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from seqeval.metrics import classification_report as seq_classification_report\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import random\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output"
      ],
      "metadata": {
        "id": "VOeM3A4OmZRw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Memuat dataset dari file JSON\n",
        "with open('dataaa.json', 'r', encoding='utf-8') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Mengubah dataset menjadi DataFrame\n",
        "df = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "dXze4_nxmbdB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menentukan jumlah sampel maksimum per intent\n",
        "max_samples = 50\n",
        "\n",
        "df_list = []\n",
        "for intent in df['intent'].unique():\n",
        "    df_intent = df[df['intent'] == intent]\n",
        "    if len(df_intent) > max_samples:\n",
        "        df_intent = resample(df_intent, replace=False, n_samples=max_samples, random_state=42)\n",
        "    df_list.append(df_intent)\n",
        "\n",
        "df_balanced = pd.concat(df_list).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "G24GnC0ymoFF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode intents\n",
        "label_encoder = LabelEncoder()\n",
        "df_balanced['intent_label'] = label_encoder.fit_transform(df_balanced['intent'])\n",
        "\n",
        "# Simpan mapping label untuk penggunaan nanti\n",
        "intent_mapping = dict(zip(df_balanced['intent_label'], df_balanced['intent']))"
      ],
      "metadata": {
        "id": "3rogszPXmqH_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Memfilter data yang memiliki entitas\n",
        "df_ner = df[df['entities'].map(lambda d: len(d)) > 0].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "xbLPP3P4msf0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "Wt6R1dlfmugc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = df_balanced['utterances'].apply(clean_text).tolist()\n",
        "labels = df_balanced['intent_label'].tolist()\n",
        "\n",
        "# Split the data\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    texts,\n",
        "    labels,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=labels\n",
        ")"
      ],
      "metadata": {
        "id": "lRKfSLvAmwL1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat tokenizer\n",
        "tokenizer = Tokenizer(oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(train_texts)\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(word_index) + 1\n",
        "\n",
        "# Mengonversi teks ke sequences\n",
        "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
        "val_sequences = tokenizer.texts_to_sequences(val_texts)\n",
        "\n",
        "# Padding sequences\n",
        "max_seq_length = max(max(len(seq) for seq in train_sequences), max(len(seq) for seq in val_sequences))\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_seq_length, padding='post')\n",
        "val_padded = pad_sequences(val_sequences, maxlen=max_seq_length, padding='post')\n",
        "\n",
        "# Mengonversi labels ke categorical\n",
        "num_classes = len(label_encoder.classes_)\n",
        "train_labels_cat = to_categorical(train_labels, num_classes=num_classes)\n",
        "val_labels_cat = to_categorical(val_labels, num_classes=num_classes)"
      ],
      "metadata": {
        "id": "zi2rgRONmyL8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_ner_data(df, tokenizer, max_seq_length):\n",
        "    texts = []\n",
        "    labels = []\n",
        "    for index, row in df.iterrows():\n",
        "        text = clean_text(row['utterances'])\n",
        "        entities = row['entities']\n",
        "        tokens = tokenizer.texts_to_sequences([text])[0]\n",
        "        label_seq = ['O'] * len(tokens)\n",
        "        for ent in entities:\n",
        "            ent_text = clean_text(ent['value'])\n",
        "            ent_tokens = tokenizer.texts_to_sequences([ent_text])[0]\n",
        "            for i in range(len(tokens)):\n",
        "                if tokens[i:i+len(ent_tokens)] == ent_tokens:\n",
        "                    label_seq[i] = 'B-' + ent['entity']\n",
        "                    for j in range(1, len(ent_tokens)):\n",
        "                        label_seq[i+j] = 'I-' + ent['entity']\n",
        "                    break\n",
        "        texts.append(tokens)\n",
        "        labels.append(label_seq)\n",
        "    # Padding\n",
        "    texts_padded = pad_sequences(texts, maxlen=max_seq_length, padding='post')\n",
        "    return texts_padded, labels\n",
        "\n",
        "# Membuat label encoder untuk NER\n",
        "all_labels = set()\n",
        "for labels in df_ner['entities']:\n",
        "    for ent in labels:\n",
        "        all_labels.add('B-' + ent['entity'])\n",
        "        all_labels.add('I-' + ent['entity'])\n",
        "all_labels.add('O')\n",
        "ner_label_encoder = {label: idx for idx, label in enumerate(sorted(all_labels))}\n",
        "ner_label_decoder = {idx: label for label, idx in ner_label_encoder.items()}\n",
        "\n",
        "# Siapkan data NER\n",
        "train_texts_ner, train_labels_ner = prepare_ner_data(df_ner, tokenizer, max_seq_length)"
      ],
      "metadata": {
        "id": "h-4l1sQum0SX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "\n",
        "model_intent = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=128, input_length=max_seq_length),\n",
        "    Bidirectional(LSTM(64)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model_intent.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJWN3mg9m2Tu",
        "outputId": "385562f1-2542-418a-bbeb-cdc084e3f3db"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=2),\n",
        "    ModelCheckpoint(\n",
        "        filepath='best_model_intent.h5',  # Nama file untuk menyimpan seluruh model\n",
        "        save_best_only=True,\n",
        "        save_weights_only=False  # Bisa dihapus karena default-nya sudah False\n",
        "    )\n",
        "]\n",
        "\n",
        "history_intent = model_intent.fit(\n",
        "    train_padded,\n",
        "    train_labels_cat,\n",
        "    validation_data=(val_padded, val_labels_cat),\n",
        "    epochs=10,\n",
        "    batch_size=16,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "K4Ao-ODqoJmy",
        "outputId": "3b922f0c-a0fb-4123-ea59-5a21f125f863"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The filepath provided must end in `.keras` (Keras model format). Received: filepath=best_model_intent.h5",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-cae5fa2540b2>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m callbacks = [\n\u001b[1;32m      3\u001b[0m     \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     ModelCheckpoint(\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'best_model_intent.h5'\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Nama file untuk menyimpan seluruh model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks/model_checkpoint.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filepath, monitor, verbose, save_best_only, save_weights_only, mode, save_freq, initial_value_threshold)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".keras\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    192\u001b[0m                     \u001b[0;34m\"The filepath provided must end in `.keras` \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m                     \u001b[0;34m\"(Keras model format). Received: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The filepath provided must end in `.keras` (Keras model format). Received: filepath=best_model_intent.h5"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=2),\n",
        "    ModelCheckpoint(\n",
        "        filepath='best_model_intent.weights.h5',  # Ubah nama file di sini\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True\n",
        "    )\n",
        "]\n",
        "\n",
        "history_intent = model_intent.fit(\n",
        "    train_padded,\n",
        "    train_labels_cat,\n",
        "    validation_data=(val_padded, val_labels_cat),\n",
        "    epochs=10,\n",
        "    batch_size=16,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPngEnbhm5I-",
        "outputId": "77fe0bf0-bf15-45c9-b60b-10304b8d4a9e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0097 - val_accuracy: 0.9615 - val_loss: 0.0990\n",
            "Epoch 2/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.9487 - val_loss: 0.0981\n",
            "Epoch 3/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.9615 - val_loss: 0.1066\n",
            "Epoch 4/10\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0043 - val_accuracy: 0.9615 - val_loss: 0.1105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_ner_labels(labels, max_seq_length, ner_label_encoder):\n",
        "    labels_encoded = []\n",
        "    for label_seq in labels:\n",
        "        label_ids = [ner_label_encoder[label] for label in label_seq]\n",
        "        label_ids = label_ids + [ner_label_encoder['O']] * (max_seq_length - len(label_ids))\n",
        "        labels_encoded.append(label_ids)\n",
        "    labels_encoded = np.array(labels_encoded)\n",
        "    labels_encoded = to_categorical(labels_encoded, num_classes=len(ner_label_encoder))\n",
        "    return labels_encoded\n",
        "\n",
        "train_labels_ner_encoded = encode_ner_labels(train_labels_ner, max_seq_length, ner_label_encoder)"
      ],
      "metadata": {
        "id": "3scc2TNom7vB"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import TimeDistributed, Bidirectional\n",
        "\n",
        "model_ner = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=128, input_length=max_seq_length),\n",
        "    Bidirectional(LSTM(64, return_sequences=True)),\n",
        "    TimeDistributed(Dense(len(ner_label_encoder), activation='softmax'))\n",
        "])\n",
        "\n",
        "model_ner.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "9P00jlmLn38L"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks\n",
        "callbacks_ner = [\n",
        "    EarlyStopping(monitor='val_loss', patience=2),\n",
        "    ModelCheckpoint(\n",
        "        filepath='best_model_ner.weights.h5',\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True\n",
        "    )\n",
        "]\n",
        "\n",
        "history_ner = model_ner.fit(\n",
        "    train_texts_ner,\n",
        "    train_labels_ner_encoded,\n",
        "    validation_split=0.1,\n",
        "    epochs=10,\n",
        "    batch_size=16,\n",
        "    callbacks=callbacks_ner\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmW9jTcwoR7F",
        "outputId": "fc63d87b-a105-4656-d774-54882484b669"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 71ms/step - accuracy: 0.5653 - loss: 2.1907 - val_accuracy: 0.9120 - val_loss: 0.7124\n",
            "Epoch 2/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7411 - loss: 1.0118 - val_accuracy: 0.9120 - val_loss: 0.6026\n",
            "Epoch 3/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7386 - loss: 0.8122 - val_accuracy: 0.9120 - val_loss: 0.5604\n",
            "Epoch 4/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7260 - loss: 0.7389 - val_accuracy: 0.9120 - val_loss: 0.4325\n",
            "Epoch 5/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7561 - loss: 0.6261 - val_accuracy: 0.9120 - val_loss: 0.3436\n",
            "Epoch 6/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8188 - loss: 0.5329 - val_accuracy: 0.9120 - val_loss: 0.2563\n",
            "Epoch 7/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8660 - loss: 0.4400 - val_accuracy: 0.9375 - val_loss: 0.1971\n",
            "Epoch 8/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8775 - loss: 0.3730 - val_accuracy: 0.9537 - val_loss: 0.1560\n",
            "Epoch 9/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9039 - loss: 0.3050 - val_accuracy: 0.9375 - val_loss: 0.1808\n",
            "Epoch 10/10\n",
            "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9088 - loss: 0.2715 - val_accuracy: 0.9421 - val_loss: 0.1501\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load best weights\n",
        "model_intent.load_weights('best_model_intent.weights.h5')\n",
        "\n",
        "# Evaluasi\n",
        "loss, accuracy = model_intent.evaluate(val_padded, val_labels_cat)\n",
        "print(f'Akurasi Model Klasifikasi Intent: {accuracy * 100:.2f}%')\n",
        "\n",
        "# Predict on validation data\n",
        "val_preds = model_intent.predict(val_padded)\n",
        "val_preds = np.argmax(val_preds, axis=1)\n",
        "val_true = np.argmax(val_labels_cat, axis=1)\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(val_true, val_preds, target_names=label_encoder.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5xGKWpYoUTi",
        "outputId": "d2144028-4fcf-479a-865d-a0e8baf3aa92"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9548 - loss: 0.1035 \n",
            "Akurasi Model Klasifikasi Intent: 94.87%\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
            "                        precision    recall  f1-score   support\n",
            "\n",
            "        cat_healthcare       1.00      1.00      1.00         6\n",
            "disease_prevention_cat       1.00      1.00      1.00        10\n",
            "disease_prevention_dog       0.89      1.00      0.94         8\n",
            "        dog_healthcare       1.00      0.88      0.93         8\n",
            "  general_conversation       0.90      0.90      0.90        10\n",
            "   medical_inquiry_cat       1.00      1.00      1.00        10\n",
            "   medical_inquiry_dog       0.91      1.00      0.95        10\n",
            "  science_conversation       0.88      0.88      0.88         8\n",
            "  symptom_analysis_cat       1.00      1.00      1.00         4\n",
            "  symptom_analysis_dog       1.00      0.75      0.86         4\n",
            "\n",
            "              accuracy                           0.95        78\n",
            "             macro avg       0.96      0.94      0.95        78\n",
            "          weighted avg       0.95      0.95      0.95        78\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load best weights\n",
        "model_ner.load_weights('best_model_ner.weights.h5')\n",
        "\n",
        "# Evaluasi\n",
        "loss, accuracy = model_ner.evaluate(train_texts_ner, train_labels_ner_encoded)\n",
        "print(f'Akurasi Model NER: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOENszaJogLw",
        "outputId": "95dd9586-1af1-4019-dec4-a63cea88ea89"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9107 - loss: 0.2630\n",
            "Akurasi Model NER: 92.45%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simpan model dan tokenizer\n",
        "model_intent.save('model_intent.h5')\n",
        "model_ner.save('model_ner.h5')\n",
        "import pickle\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('label_encoder.pickle', 'wb') as handle:\n",
        "    pickle.dump(label_encoder, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "with open('ner_label_encoder.pickle', 'wb') as handle:\n",
        "    pickle.dump(ner_label_encoder, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Z6em3i9o614",
        "outputId": "5e59f587-bb21-4508-c75b-51332934d0bb"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Memuat model dan tokenizer\n",
        "from tensorflow.keras.models import load_model\n",
        "model_intent = load_model('model_intent.h5')\n",
        "model_ner = load_model('model_ner.h5')\n",
        "\n",
        "import pickle\n",
        "with open('tokenizer.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)\n",
        "with open('label_encoder.pickle', 'rb') as handle:\n",
        "    label_encoder = pickle.load(handle)\n",
        "with open('ner_label_encoder.pickle', 'rb') as handle:\n",
        "    ner_label_encoder = pickle.load(handle)\n",
        "ner_label_decoder = {idx: label for label, idx in ner_label_encoder.items()}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CITTe6WipIXR",
        "outputId": "53c280ef-2c0e-4d28-c1aa-570ee8286d07"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_intent(text):\n",
        "    text_clean = clean_text(text)\n",
        "    seq = tokenizer.texts_to_sequences([text_clean])\n",
        "    padded_seq = pad_sequences(seq, maxlen=max_seq_length, padding='post')\n",
        "    pred = model_intent.predict(padded_seq)\n",
        "    predicted_label = np.argmax(pred, axis=1)[0]\n",
        "    intent = label_encoder.inverse_transform([predicted_label])[0]\n",
        "    return intent"
      ],
      "metadata": {
        "id": "YvnGU5YZpLFE"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_entities(text):\n",
        "    text_clean = clean_text(text)\n",
        "    seq = tokenizer.texts_to_sequences([text_clean])\n",
        "    padded_seq = pad_sequences(seq, maxlen=max_seq_length, padding='post')\n",
        "    pred = model_ner.predict(padded_seq)\n",
        "    pred_labels = np.argmax(pred, axis=-1)[0]\n",
        "    tokens = tokenizer.sequences_to_texts(seq)[0].split()\n",
        "    entities = []\n",
        "    for idx, label_id in enumerate(pred_labels[:len(tokens)]):\n",
        "        label = ner_label_decoder[label_id]\n",
        "        if label != 'O':\n",
        "            entities.append({'entity': label.split('-')[1], 'value': tokens[idx]})\n",
        "    return entities"
      ],
      "metadata": {
        "id": "fNk1VEtNpOVQ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat DataFrame utterances dan responses\n",
        "df_utterances = df_balanced[['utterances', 'responses']].reset_index(drop=True)\n",
        "df_utterances['utterances_clean'] = df_utterances['utterances'].apply(clean_text)\n",
        "\n",
        "# Menghitung TF-IDF matrix\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(df_utterances['utterances_clean'])"
      ],
      "metadata": {
        "id": "MQcbVyYppQiH"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_response(user_input):\n",
        "    # Clean user input\n",
        "    user_input_clean = clean_text(user_input)\n",
        "    # Transform input pengguna\n",
        "    user_tfidf = vectorizer.transform([user_input_clean])\n",
        "\n",
        "    # Hitung cosine similarity\n",
        "    similarities = cosine_similarity(user_tfidf, tfidf_matrix)\n",
        "\n",
        "    # Dapatkan indeks dengan similarity tertinggi\n",
        "    most_similar_idx = np.argmax(similarities[0])\n",
        "\n",
        "    # Jika similarity rendah, berikan respon default\n",
        "    if similarities[0][most_similar_idx] < 0.2:\n",
        "        return \"Maaf, saya tidak memahami pertanyaan Anda.\"\n",
        "\n",
        "    # Ambil respon yang sesuai\n",
        "    response = df_utterances.iloc[most_similar_idx]['responses']\n",
        "\n",
        "    return response"
      ],
      "metadata": {
        "id": "tLtjPY7xpTBU"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot_response(user_input):\n",
        "    # Prediksi intent dan entitas\n",
        "    intent = predict_intent(user_input)\n",
        "    entities = predict_entities(user_input)\n",
        "    response = get_response(user_input)\n",
        "    # Modifikasi respon berdasarkan entitas jika diperlukan\n",
        "    return response"
      ],
      "metadata": {
        "id": "X8XbhMHQpaEz"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat widget input dan output\n",
        "input_box = widgets.Text(\n",
        "    value='',\n",
        "    placeholder='Ketik pesan Anda...',\n",
        "    description='Anda:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "output_area = widgets.Output()\n",
        "\n",
        "def on_submit(sender):\n",
        "    user_input = input_box.value\n",
        "    input_box.value = ''\n",
        "    response = chatbot_response(user_input)\n",
        "    with output_area:\n",
        "        print(f\"Anda: {user_input}\")\n",
        "        print(f\"Chatbot: {response}\\n\")\n",
        "\n",
        "input_box.on_submit(on_submit)\n",
        "\n",
        "display(input_box, output_area)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918,
          "referenced_widgets": [
            "ddce7e299bd04ffeb116b31c1378757f",
            "e32daa61bdbf46c4b414021bacb734b3",
            "4dd6e7a0dca74d5f819bc01152a0fd87",
            "b2136a2d2d7d435781e8a6045665bd09",
            "80e6b317d8e144f687cadafa4d776248"
          ]
        },
        "id": "U9qx3qILpcWY",
        "outputId": "5d613f64-f2a6-411c-b3a3-000e8f75b92c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Text(value='', description='Anda:', placeholder='Ketik pesan Anda...')"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ddce7e299bd04ffeb116b31c1378757f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b2136a2d2d7d435781e8a6045665bd09"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Contoh kalimat\n",
        "test_sentence = \"kucing saya sering muntah dan tidak mau makan.\"\n",
        "\n",
        "# Prediksi intent\n",
        "predicted_intent = predict_intent(test_sentence)\n",
        "print(f\"Intent yang diprediksi: {predicted_intent}\")\n",
        "\n",
        "# Prediksi entitas\n",
        "predicted_entities = predict_entities(test_sentence)\n",
        "print(\"Entitas yang ditemukan:\")\n",
        "for entity in predicted_entities:\n",
        "    print(f\"- {entity['entity']}: {entity['value']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3UCBbMYpemV",
        "outputId": "342dcbb8-d66b-4f9e-cdb2-9b8310a11a13"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Intent yang diprediksi: symptom_analysis_cat\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Entitas yang ditemukan:\n",
            "- animal: kucing\n",
            "- symptom: sering\n",
            "- symptom: muntah\n",
            "- symptom: tidak\n",
            "- symptom: mau\n",
            "- symptom: makan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IT-GE_s6qWhg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}