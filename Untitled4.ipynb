{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyOb9vD5ToU/Ir9XQolCD+il",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bryanbayup/Machine-Learning/blob/main/Untitled4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalasi Library Tambahan\n",
        "!pip install gensim keras-tuner imbalanced-learn Sastrawi sentencepiece seqeval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hy1FZwE59O-q",
        "outputId": "e677b4c5-e0ae-44de-95d6-8a16fb27b101"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.3)\n",
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.10/dist-packages (1.4.7)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.12.4)\n",
            "Requirement already satisfied: Sastrawi in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (7.0.5)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (3.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.32.3)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (1.0.5)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.5.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim) (1.16.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.13.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras->keras-tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout, Bidirectional, LSTM, Conv1D, GlobalMaxPooling1D, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import pickle\n",
        "import os\n",
        "import random\n",
        "import nltk\n",
        "import gensim\n",
        "from gensim.models import KeyedVectors\n",
        "from keras_tuner import HyperModel, RandomSearch\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "from nltk.corpus import stopwords\n",
        "from seqeval.metrics import classification_report as seq_classification_report\n",
        "\n",
        "# Download NLTK stopwords\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHUP4uFD9S9S",
        "outputId": "1f897d9b-d911-474a-a1a9-5763b723e914"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Download FastText\n",
        "# !wget -O id.tar.gz \"https://www.dropbox.com/scl/fi/sju4o3keikox69euw51vy/id.tar.gz?rlkey=5jr3ijtbdwfahq7xcgig28qvy&e=1&st=gntzkzeo&dl=1\"\n",
        "# !tar -xzf id.tar.gz\n",
        "\n",
        "# Load FastText\n",
        "try:\n",
        "    fasttext_model = KeyedVectors.load_word2vec_format('id.vec', binary=False)\n",
        "    print(\"FastText 'id.vec' berhasil dimuat.\")\n",
        "except Exception as e:\n",
        "    print(f\"Gagal memuat 'id.vec': {e}\")\n",
        "    raise ValueError(\"Gagal memuat FastText.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UT5Om1un9WR9",
        "outputId": "d1a6805d-660d-4f17-82c8-4624638cd203"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastText 'id.vec' berhasil dimuat.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Memuat dataset dari file JSON\n",
        "with open('dataaa.json', 'r', encoding='utf-8') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# Mengubah dataset menjadi DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Penyesuaian nama kolom untuk konsistensi\n",
        "df.rename(columns={'utterance': 'utterances', 'response': 'responses'}, inplace=True)"
      ],
      "metadata": {
        "id": "e-Oe071h9alh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode intents\n",
        "label_encoder = LabelEncoder()\n",
        "df['intent_label'] = label_encoder.fit_transform(df['intent'])\n",
        "\n",
        "# Save intent mapping\n",
        "intent_mapping = dict(zip(df['intent_label'], df['intent']))\n",
        "\n",
        "# Menangani ketidakseimbangan data dengan oversampling\n",
        "ros = RandomOverSampler(random_state=42)\n",
        "X = df.index.values.reshape(-1, 1)\n",
        "y = df['intent_label']\n",
        "X_ros, y_ros = ros.fit_resample(X, y)\n",
        "\n",
        "# Membuat DataFrame baru dengan data yang telah dioversample\n",
        "df_balanced = df.loc[X_ros.flatten()].reset_index(drop=True)\n",
        "df_balanced['intent_label'] = y_ros\n",
        "df_balanced['intent'] = label_encoder.inverse_transform(df_balanced['intent_label'])"
      ],
      "metadata": {
        "id": "QZWTn0P29dly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Text cleaning function\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    return text\n",
        "\n",
        "# Memuat stopwords\n",
        "with open('stopword_list_tala.txt', 'r', encoding='utf-8') as f:\n",
        "    stop_words = f.read().splitlines()\n",
        "stop_words = set(word.strip().lower() for word in stop_words)  # Pastikan lowercase dan tanpa spasi\n",
        "\n",
        "# Stemming dengan Sastrawi\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "\n",
        "# Fungsi preprocessing teks\n",
        "def preprocess_text(text):\n",
        "    # Konversi teks menjadi huruf kecil dan hapus tanda baca\n",
        "    text = clean_text(text)\n",
        "    # Tokenisasi\n",
        "    tokens = text.split()\n",
        "    # Penghapusan stopwords\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    # Stemming\n",
        "    tokens_after_stemming = [stemmer.stem(token) for token in tokens]\n",
        "    # Gabungkan kembali tokens menjadi string\n",
        "    text = ' '.join(tokens_after_stemming)\n",
        "    return text\n",
        "\n",
        "# Apply preprocessing\n",
        "df_balanced['utterances_clean'] = df_balanced['utterances'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "HYGOLdN-9gWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare texts and labels\n",
        "texts = df_balanced['utterances_clean'].tolist()\n",
        "labels = df_balanced['intent_label'].tolist()\n",
        "\n",
        "# Split data untuk Klasifikasi Intents\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    texts,\n",
        "    labels,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=labels\n",
        ")\n",
        "\n",
        "# Tokenisasi teks\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token='')\n",
        "tokenizer.fit_on_texts(train_texts)\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(word_index) + 1\n",
        "\n",
        "# Convert texts to sequences\n",
        "train_sequences = tokenizer.texts_to_sequences(train_texts)\n",
        "val_sequences = tokenizer.texts_to_sequences(val_texts)\n",
        "\n",
        "# Padding sequences\n",
        "max_seq_length = max(max(len(seq) for seq in train_sequences), max(len(seq) for seq in val_sequences))\n",
        "train_padded = pad_sequences(train_sequences, maxlen=max_seq_length, padding='post')\n",
        "val_padded = pad_sequences(val_sequences, maxlen=max_seq_length, padding='post')\n",
        "\n",
        "# Convert labels to categorical\n",
        "num_classes = len(label_encoder.classes_)\n",
        "train_labels_cat = to_categorical(train_labels, num_classes=num_classes)\n",
        "val_labels_cat = to_categorical(val_labels, num_classes=num_classes)\n",
        "\n",
        "# Buat matriks embedding menggunakan FastText\n",
        "embedding_dim = fasttext_model.vector_size\n",
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, idx in word_index.items():\n",
        "    if word in fasttext_model:\n",
        "        embedding_matrix[idx] = fasttext_model[word]\n",
        "    else:\n",
        "        embedding_matrix[idx] = np.random.normal(scale=0.6, size=(embedding_dim,))"
      ],
      "metadata": {
        "id": "-iesIHGK9ijt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter data dengan entities\n",
        "df_ner = df[df['entities'].map(lambda d: len(d)) > 0].reset_index(drop=True)\n",
        "df_ner['utterances_clean'] = df_ner['utterances'].apply(preprocess_text)\n",
        "\n",
        "def prepare_ner_data(df, tokenizer, max_seq_length):\n",
        "    texts = []\n",
        "    labels = []\n",
        "    for index, row in df.iterrows():\n",
        "        text = row['utterances_clean']\n",
        "        entities = row['entities']\n",
        "        tokens = tokenizer.texts_to_sequences([text])[0]\n",
        "        label_seq = ['O'] * len(tokens)\n",
        "        for ent in entities:\n",
        "            ent_text = preprocess_text(ent['value'])\n",
        "            ent_tokens = tokenizer.texts_to_sequences([ent_text])[0]\n",
        "            ent_len = len(ent_tokens)\n",
        "            for i in range(len(tokens) - ent_len + 1):\n",
        "                if tokens[i:i+ent_len] == ent_tokens:\n",
        "                    label_seq[i] = 'B-' + ent['entity']\n",
        "                    for j in range(1, ent_len):\n",
        "                        label_seq[i+j] = 'I-' + ent['entity']\n",
        "                    break\n",
        "        texts.append(tokens)\n",
        "        labels.append(label_seq)\n",
        "    # Padding\n",
        "    texts_padded = pad_sequences(texts, maxlen=max_seq_length, padding='post')\n",
        "    # Padding labels\n",
        "    labels_padded = [label + ['O']*(max_seq_length - len(label)) for label in labels]\n",
        "    return texts_padded, labels_padded\n",
        "\n",
        "# Buat label encoder untuk NER\n",
        "all_labels = set()\n",
        "for label_list in df_ner['entities']:\n",
        "    for ent in label_list:\n",
        "        all_labels.add('B-' + ent['entity'])\n",
        "        all_labels.add('I-' + ent['entity'])\n",
        "all_labels.add('O')\n",
        "ner_label_encoder = {label: idx for idx, label in enumerate(sorted(all_labels))}\n",
        "ner_label_decoder = {idx: label for label, idx in ner_label_encoder.items()}\n",
        "\n",
        "# Prepare NER data\n",
        "texts_ner, labels_ner = prepare_ner_data(df_ner, tokenizer, max_seq_length)\n",
        "\n",
        "# Convert labels to numerical and categorical format\n",
        "def encode_ner_labels(labels, ner_label_encoder):\n",
        "    labels_encoded = []\n",
        "    for label_seq in labels:\n",
        "        label_ids = [ner_label_encoder[label] for label in label_seq]\n",
        "        labels_encoded.append(label_ids)\n",
        "    labels_encoded = np.array(labels_encoded)\n",
        "    labels_encoded = to_categorical(labels_encoded, num_classes=len(ner_label_encoder))\n",
        "    return labels_encoded\n",
        "\n",
        "labels_ner_encoded = encode_ner_labels(labels_ner, ner_label_encoder)\n",
        "\n",
        "# Split data untuk NER\n",
        "train_texts_ner, val_texts_ner, train_labels_ner, val_labels_ner = train_test_split(\n",
        "    texts_ner,\n",
        "    labels_ner_encoded,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        ")"
      ],
      "metadata": {
        "id": "gOaF2HSV9m84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_intent_model_with_cnn(embedding_matrix, max_seq_length, num_classes, l2_reg=0.001):\n",
        "    inputs = Input(shape=(max_seq_length,))\n",
        "    embedding = tf.keras.layers.Embedding(\n",
        "        input_dim=embedding_matrix.shape[0],\n",
        "        output_dim=embedding_matrix.shape[1],\n",
        "        weights=[embedding_matrix],\n",
        "        input_length=max_seq_length,\n",
        "        trainable=True\n",
        "    )(inputs)\n",
        "    conv = Conv1D(filters=128, kernel_size=3, activation='relu')(embedding)\n",
        "    global_pool = GlobalMaxPooling1D()(conv)\n",
        "    dense = Dense(64, activation='relu', kernel_regularizer=l2(l2_reg))(global_pool)\n",
        "    dropout = Dropout(0.5)(dense)\n",
        "    outputs = Dense(num_classes, activation='softmax')(dropout)\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "model_intent_cnn = build_intent_model_with_cnn(embedding_matrix, max_seq_length, num_classes, l2_reg=0.001)\n",
        "model_intent_cnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_intent_cnn.summary()\n",
        "\n",
        "# Early stopping\n",
        "callbacks_intent = [\n",
        "    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "]\n",
        "\n",
        "# Melatih model\n",
        "history_intent_cnn = model_intent_cnn.fit(\n",
        "    train_padded,\n",
        "    train_labels_cat,\n",
        "    validation_data=(val_padded, val_labels_cat),\n",
        "    epochs=20,\n",
        "    batch_size=16,\n",
        "    callbacks=callbacks_intent\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861
        },
        "id": "eDZXtsnV9peu",
        "outputId": "d14ac443-e7f7-4638-deb9-5315f3bc323c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21\u001b[0m, \u001b[38;5;34m300\u001b[0m)             │         \u001b[38;5;34m192,900\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │         \u001b[38;5;34m115,328\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_max_pooling1d                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)                  │           \u001b[38;5;34m3,640\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">192,900</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">115,328</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_max_pooling1d                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,640</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m320,124\u001b[0m (1.22 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">320,124</span> (1.22 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m320,124\u001b[0m (1.22 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">320,124</span> (1.22 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.1250 - loss: 3.7593 - val_accuracy: 0.7080 - val_loss: 2.0677\n",
            "Epoch 2/20\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.5591 - loss: 1.9692 - val_accuracy: 0.8497 - val_loss: 0.8663\n",
            "Epoch 3/20\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - accuracy: 0.7690 - loss: 1.0721 - val_accuracy: 0.9161 - val_loss: 0.5240\n",
            "Epoch 4/20\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.8503 - loss: 0.7207 - val_accuracy: 0.9213 - val_loss: 0.3976\n",
            "Epoch 5/20\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8922 - loss: 0.5073 - val_accuracy: 0.9266 - val_loss: 0.3549\n",
            "Epoch 6/20\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9186 - loss: 0.4239 - val_accuracy: 0.9318 - val_loss: 0.3265\n",
            "Epoch 7/20\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9333 - loss: 0.3521 - val_accuracy: 0.9248 - val_loss: 0.3230\n",
            "Epoch 8/20\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9500 - loss: 0.3067 - val_accuracy: 0.9388 - val_loss: 0.3114\n",
            "Epoch 9/20\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9569 - loss: 0.2666 - val_accuracy: 0.9336 - val_loss: 0.3075\n",
            "Epoch 10/20\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - accuracy: 0.9672 - loss: 0.2492 - val_accuracy: 0.9371 - val_loss: 0.3049\n",
            "Epoch 11/20\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9644 - loss: 0.2285 - val_accuracy: 0.9353 - val_loss: 0.3069\n",
            "Epoch 12/20\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9700 - loss: 0.2282 - val_accuracy: 0.9371 - val_loss: 0.3100\n",
            "Epoch 13/20\n",
            "\u001b[1m143/143\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9725 - loss: 0.2032 - val_accuracy: 0.9318 - val_loss: 0.3121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NERHyperModel(HyperModel):\n",
        "    def __init__(self, embedding_matrix, max_seq_length, num_entities):\n",
        "        self.embedding_matrix = embedding_matrix\n",
        "        self.max_seq_length = max_seq_length\n",
        "        self.num_entities = num_entities\n",
        "\n",
        "    def build(self, hp):\n",
        "        l2_reg = hp.Choice('l2_reg', values=[1e-4, 1e-3, 1e-2])\n",
        "        dropout_rate = hp.Float('dropout_rate', 0.3, 0.7, step=0.1)\n",
        "        lstm_units = hp.Int('lstm_units', min_value=32, max_value=128, step=32)\n",
        "\n",
        "        inputs = Input(shape=(self.max_seq_length,))\n",
        "        embedding = tf.keras.layers.Embedding(\n",
        "            input_dim=self.embedding_matrix.shape[0],\n",
        "            output_dim=self.embedding_matrix.shape[1],\n",
        "            weights=[self.embedding_matrix],\n",
        "            input_length=self.max_seq_length,\n",
        "            trainable=True\n",
        "        )(inputs)\n",
        "        lstm = Bidirectional(LSTM(lstm_units, kernel_regularizer=l2(l2_reg), return_sequences=True))(embedding)\n",
        "        dropout = Dropout(dropout_rate)(lstm)\n",
        "        outputs = TimeDistributed(Dense(self.num_entities, activation='softmax'))(dropout)\n",
        "        model = Model(inputs=inputs, outputs=outputs)\n",
        "        model.compile(\n",
        "            optimizer='adam',\n",
        "            loss='categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "        return model\n",
        "\n",
        "# Initialize HyperModel\n",
        "ner_hypermodel = NERHyperModel(embedding_matrix, max_seq_length, len(ner_label_encoder))\n",
        "\n",
        "# Initialize RandomSearch\n",
        "tuner_ner = RandomSearch(\n",
        "    ner_hypermodel,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=10,\n",
        "    executions_per_trial=1,\n",
        "    directory='ner_tuner_dir',\n",
        "    project_name='ner_tuning'\n",
        ")\n",
        "\n",
        "# Hyperparameter search for NER\n",
        "tuner_ner.search(\n",
        "    train_texts_ner,\n",
        "    train_labels_ner,\n",
        "    epochs=10,\n",
        "    validation_data=(val_texts_ner, val_labels_ner),\n",
        "    callbacks=[\n",
        "        EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Get the best model for NER\n",
        "best_model_ner = tuner_ner.get_best_models(num_models=1)[0]\n",
        "best_hp_ner = tuner_ner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(f\"Best Hyperparameters for NER: {best_hp_ner.values}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvQnIddx9swk",
        "outputId": "5eff6f36-5b73-4e03-8e91-4cf4b43c8a1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 00m 27s]\n",
            "val_accuracy: 0.9398852586746216\n",
            "\n",
            "Best val_accuracy So Far: 0.9459642171859741\n",
            "Total elapsed time: 00h 04m 38s\n",
            "Best Hyperparameters for NER: {'l2_reg': 0.001, 'dropout_rate': 0.3, 'lstm_units': 128}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 20 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluasi Model Intent Classification\n",
        "loss_intent, accuracy_intent = model_intent_cnn.evaluate(val_padded, val_labels_cat)\n",
        "print(f'Akurasi Model Klasifikasi Intent: {accuracy_intent * 100:.2f}%')\n",
        "\n",
        "# Evaluasi Model NER\n",
        "loss_ner, accuracy_ner = best_model_ner.evaluate(val_texts_ner, val_labels_ner)\n",
        "print(f'Akurasi Model NER: {accuracy_ner * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9WJDS1E93U4",
        "outputId": "41f7ec2f-ae8d-4aeb-b074-cfdd0ab7d5dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9343 - loss: 0.2910\n",
            "Akurasi Model Klasifikasi Intent: 93.71%\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9442 - loss: 0.2791\n",
            "Akurasi Model NER: 94.60%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat direktori\n",
        "os.makedirs('models', exist_ok=True)\n",
        "os.makedirs('encoders', exist_ok=True)\n",
        "os.makedirs('data', exist_ok=True)\n",
        "\n",
        "# Save intent model\n",
        "model_intent_cnn.save('models/model_intent.keras')\n",
        "\n",
        "# Save NER model\n",
        "best_model_ner.save('models/model_ner.keras')\n",
        "\n",
        "# Save tokenizer\n",
        "with open('encoders/tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# Save label encoder\n",
        "with open('encoders/label_encoder.pickle', 'wb') as handle:\n",
        "    pickle.dump(label_encoder, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# Save NER label encoder\n",
        "with open('encoders/ner_label_encoder.pickle', 'wb') as handle:\n",
        "    pickle.dump(ner_label_encoder, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "Ig_Rk2zS9_w5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame for utterances and responses\n",
        "df_utterances = df_balanced[['utterances', 'responses', 'intent']].reset_index(drop=True)\n",
        "df_utterances['utterances_clean'] = df_utterances['utterances'].apply(preprocess_text)\n",
        "\n",
        "# Create TF-IDF Vectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorizer.fit(df_utterances['utterances_clean'])\n",
        "\n",
        "# Simpan vectorizer\n",
        "with open('data/vectorizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(vectorizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "o_UxveEW-Fem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_intent(text):\n",
        "    text_clean = preprocess_text(text)\n",
        "    seq = tokenizer.texts_to_sequences([text_clean])\n",
        "    padded_seq = pad_sequences(seq, maxlen=max_seq_length, padding='post')\n",
        "    pred = model_intent_cnn.predict(padded_seq)\n",
        "    predicted_label = np.argmax(pred, axis=1)[0]\n",
        "    intent = label_encoder.inverse_transform([predicted_label])[0]\n",
        "    return intent\n",
        "\n",
        "def predict_entities(text):\n",
        "    text_clean = preprocess_text(text)\n",
        "    seq = tokenizer.texts_to_sequences([text_clean])\n",
        "    padded_seq = pad_sequences(seq, maxlen=max_seq_length, padding='post')\n",
        "    pred = best_model_ner.predict(padded_seq)\n",
        "    pred_labels = np.argmax(pred, axis=-1)[0]\n",
        "    tokens = tokenizer.sequences_to_texts(seq)[0].split()\n",
        "    entities = []\n",
        "    for idx, label_id in enumerate(pred_labels[:len(tokens)]):\n",
        "        label = ner_label_decoder[label_id]\n",
        "        if label != 'O':\n",
        "            entities.append({'entity': label.split('-')[1], 'value': tokens[idx]})\n",
        "    return entities"
      ],
      "metadata": {
        "id": "ZLBNJwp8-Hre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapping antara intent dan hewan terkait\n",
        "intent_animal_mapping = {\n",
        "    'medical_inquiry_dog': 'anjing',\n",
        "    'medical_inquiry_cat': 'kucing',\n",
        "    'symptom_analysis_dog': 'anjing',\n",
        "    'symptom_analysis_cat': 'kucing',\n",
        "    'disease_prevention_dog': 'anjing',\n",
        "    'disease_prevention_cat': 'kucing',\n",
        "    'dog_healthcare': 'anjing',\n",
        "    'cat_healthcare': 'kucing',\n",
        "    'animal_health_issue': ['anjing', 'kucing']\n",
        "}\n",
        "\n",
        "# Fungsi untuk menyesuaikan intent berdasarkan entitas\n",
        "def adjust_intent(intent, entities):\n",
        "    # Dapatkan hewan dari intent yang diprediksi\n",
        "    predicted_animal = intent_animal_mapping.get(intent, None)\n",
        "\n",
        "    # Ekstrak entitas 'animal' dari input pengguna\n",
        "    entity_animals = [ent['value'].lower() for ent in entities if ent['entity'] == 'animal']\n",
        "\n",
        "    if entity_animals:\n",
        "        user_animal = entity_animals[0]\n",
        "        if predicted_animal:\n",
        "            if isinstance(predicted_animal, list):\n",
        "                if user_animal not in predicted_animal:\n",
        "                    intent = None\n",
        "            else:\n",
        "                if predicted_animal != user_animal:\n",
        "                    for intent_name, animal in intent_animal_mapping.items():\n",
        "                        if animal == user_animal and intent_name != intent:\n",
        "                            intent = intent_name\n",
        "                            break\n",
        "                    else:\n",
        "                        intent = None\n",
        "    else:\n",
        "        # Jika tidak ada entitas 'animal', dan intent membutuhkan hewan tertentu, set intent ke None\n",
        "        if intent in intent_animal_mapping:\n",
        "            intent = None\n",
        "    return intent\n",
        "\n",
        "# Fungsi untuk mendapatkan respon berdasarkan intent yang disesuaikan\n",
        "def get_response(user_input, intent=None, entities=None):\n",
        "    user_input_clean = preprocess_text(user_input)\n",
        "    print(f\"Input yang Dipreproses: {user_input_clean}\")\n",
        "\n",
        "    if intent:\n",
        "        # Filter dataset berdasarkan intent yang disesuaikan\n",
        "        df_intent = df_utterances[df_utterances['intent'] == intent]\n",
        "        if df_intent.empty:\n",
        "            print(\"Intent tidak ditemukan dalam dataset.\")\n",
        "            return get_default_response()\n",
        "        else:\n",
        "            # Vectorize ulang utterances yang difilter\n",
        "            tfidf_matrix_intent = vectorizer.transform(df_intent['utterances_clean'])\n",
        "            user_tfidf = vectorizer.transform([user_input_clean])\n",
        "            similarities = cosine_similarity(user_tfidf, tfidf_matrix_intent)\n",
        "            most_similar_idx = np.argmax(similarities[0])\n",
        "            highest_similarity = similarities[0][most_similar_idx]\n",
        "            print(f\"Kemiripan Tertinggi: {highest_similarity}\")\n",
        "            if highest_similarity < 0.2:\n",
        "                print(\"Kemiripan di bawah threshold.\")\n",
        "                return get_default_response()\n",
        "            else:\n",
        "                # Ambil respon yang sesuai dengan utterance paling mirip\n",
        "                response = df_intent.iloc[most_similar_idx]['responses']\n",
        "                print(f\"Respon yang Dipilih: {response}\")\n",
        "                return response\n",
        "    else:\n",
        "        print(\"Intent tidak tersedia.\")\n",
        "        return get_default_response()"
      ],
      "metadata": {
        "id": "OtgGue60-gUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot_response(user_input):\n",
        "    # Prediksi intent dan entitas\n",
        "    intent = predict_intent(user_input)\n",
        "    entities = predict_entities(user_input)\n",
        "\n",
        "    # Sesuaikan intent berdasarkan entitas\n",
        "    adjusted_intent = adjust_intent(intent, entities)\n",
        "\n",
        "    print(f\"Intent yang Diprediksi: {intent}\")\n",
        "    print(f\"Entitas yang Diekstrak: {entities}\")\n",
        "    print(f\"Intent yang Disesuaikan: {adjusted_intent}\")\n",
        "\n",
        "    # Jika intent setelah disesuaikan adalah None, berikan respon default\n",
        "    if adjusted_intent is None:\n",
        "        response = get_default_response()\n",
        "    else:\n",
        "        # Dapatkan respon berdasarkan intent yang disesuaikan\n",
        "        response = get_response(user_input, adjusted_intent, entities)\n",
        "        # Jika tidak ada respon yang ditemukan, gunakan respon default\n",
        "        if not response:\n",
        "            response = get_default_response()\n",
        "    return response"
      ],
      "metadata": {
        "id": "ex81dOQt-ll6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fungsi untuk mendapatkan respon default\n",
        "def get_default_response():\n",
        "    default_responses = [\n",
        "        \"Maaf, saya belum bisa menjawab pertanyaan Anda.\",\n",
        "        \"Maaf, mohon diperjelas apa yang Anda maksud.\",\n",
        "        \"Maaf, saya hanya diprogram untuk menjawab pertanyaan mengenai kucing dan anjing.\",\n",
        "        \"Mohon maaf, saya tidak mengerti. Bisa dijelaskan lebih detail?\",\n",
        "        \"Saya belum memiliki informasi mengenai hal tersebut.\"\n",
        "    ]\n",
        "    return random.choice(default_responses)"
      ],
      "metadata": {
        "id": "SIpyyFeo-ohj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pengujian\n",
        "test_inputs = [\n",
        "    \"Hello, apakah ini aplikasi untuk membantu hewan?\",\n",
        "    \"Apa tujuan utama dari aplikasi ini?\",\n",
        "    \"Bagaimana cara laporan melalui fitur Emergency?\",\n",
        "    \"Apa fungsi utama dari fitur Emergency?\",\n",
        "    \"Bagaimana cara menggunakan fitur chatbot?\",\n",
        "    \"Apa fungsi utama dari fitur Emergency?\",\n",
        "    \"Apa tujuan dari fitur komunitas di aplikasi ini?\",\n",
        "    \"kucing saya muntah dan diare\",\n",
        "    \"anjing saya matanya bengkak\",\n",
        "    \"kucing saya demam dan flu\",\n",
        "    \"apa itu toxoplasmosis\",\n",
        "    \"AI itu apa\",\n",
        "    \"anjing tetangga suka menggonggong\",\n",
        "    \"Saya melihat seekor anjing tua tanpa kalung di kompleks. Apa yang harus saya lakukan?\",\n",
        "    \"Saya menemukan kucing dengan mata tertutup kotoran di depan pasar. Apa yang harus saya lakukan?\",\n",
        "    \"Apakah saya bisa membawa anjing ke dalam kereta api jarak jauh? Jika ya, apa yang harus disiapkan?\",\n",
        "    \"Saya ingin membawa kucing saya dalam perjalanan ke luar kota menggunakan pesawat. Apa saja yang perlu dipersiapkan?\",\n",
        "    \"Kucing saya seperti atlet parkour, suka melompat ke rak dapur dan menjatuhkan barang. Bagaimana saya bisa menghentikannya?\",\n",
        "    \"Saya melihat kucing di gang kecil yang terus mondar-mandir dengan ekspresi kebingungan\",\n",
        "    \"Ada seekor anjing besar yang tampak sakit di depan kantor saya\",\n",
        "    \"pasar itu apa\",\n",
        "    \"apa yang dimaksud dengan analisa fundamental\",\n",
        "    \"kamu tau fakta unik anjing tua\",\n",
        "    \"makasih ya\"\n",
        "]\n",
        "\n",
        "for input_text in test_inputs:\n",
        "    print(f\"Anda: {input_text}\")\n",
        "    response = chatbot_response(input_text)\n",
        "    print(f\"Chatbot: {response}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jF1MIojJ-rb5",
        "outputId": "3e8824d2-89eb-4270-ea50-e18f984846b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Anda: Hello, apakah ini aplikasi untuk membantu hewan?\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "Intent yang Diprediksi: greeting\n",
            "Entitas yang Diekstrak: []\n",
            "Intent yang Disesuaikan: greeting\n",
            "Input yang Dipreproses: hello aplikasi bantu hewan\n",
            "Kemiripan Tertinggi: 1.0000000000000002\n",
            "Respon yang Dipilih: Hello! Betul, ini adalah aplikasi untuk membantu hewan peliharaan dan hewan terlantar. Ada yang ingin Anda ketahui lebih lanjut?\n",
            "Chatbot: Hello! Betul, ini adalah aplikasi untuk membantu hewan peliharaan dan hewan terlantar. Ada yang ingin Anda ketahui lebih lanjut?\n",
            "\n",
            "Anda: Apa tujuan utama dari aplikasi ini?\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Intent yang Diprediksi: general_info\n",
            "Entitas yang Diekstrak: []\n",
            "Intent yang Disesuaikan: general_info\n",
            "Input yang Dipreproses: tuju utama aplikasi\n",
            "Kemiripan Tertinggi: 1.0000000000000002\n",
            "Respon yang Dipilih: Tujuan utama aplikasi ini adalah membantu masyarakat menangani hewan terlantar dan memberikan informasi kesehatan hewan peliharaan dengan mudah.\n",
            "Chatbot: Tujuan utama aplikasi ini adalah membantu masyarakat menangani hewan terlantar dan memberikan informasi kesehatan hewan peliharaan dengan mudah.\n",
            "\n",
            "Anda: Bagaimana cara laporan melalui fitur Emergency?\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Intent yang Diprediksi: ask_feature\n",
            "Entitas yang Diekstrak: []\n",
            "Intent yang Disesuaikan: ask_feature\n",
            "Input yang Dipreproses: lapor fitur emergency\n",
            "Kemiripan Tertinggi: 1.0\n",
            "Respon yang Dipilih: Untuk melaporkan melalui fitur Emergency, Anda hanya perlu mengisi informasi hewan seperti jenis, kondisi, dan lokasi. Laporan akan dikirim ke komunitas sukarelawan terdekat.\n",
            "Chatbot: Untuk melaporkan melalui fitur Emergency, Anda hanya perlu mengisi informasi hewan seperti jenis, kondisi, dan lokasi. Laporan akan dikirim ke komunitas sukarelawan terdekat.\n",
            "\n",
            "Anda: Apa fungsi utama dari fitur Emergency?\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Intent yang Diprediksi: ask_feature\n",
            "Entitas yang Diekstrak: []\n",
            "Intent yang Disesuaikan: ask_feature\n",
            "Input yang Dipreproses: fungsi utama fitur emergency\n",
            "Kemiripan Tertinggi: 1.0000000000000002\n",
            "Respon yang Dipilih: Fitur Emergency memungkinkan Anda melaporkan hewan terlantar atau sakit ke komunitas pecinta hewan terdekat untuk mendapatkan bantuan.\n",
            "Chatbot: Fitur Emergency memungkinkan Anda melaporkan hewan terlantar atau sakit ke komunitas pecinta hewan terdekat untuk mendapatkan bantuan.\n",
            "\n",
            "Anda: Bagaimana cara menggunakan fitur chatbot?\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Intent yang Diprediksi: ask_feature\n",
            "Entitas yang Diekstrak: []\n",
            "Intent yang Disesuaikan: ask_feature\n",
            "Input yang Dipreproses: fitur chatbot\n",
            "Kemiripan Tertinggi: 1.0\n",
            "Respon yang Dipilih: Untuk menggunakan chatbot, cukup ketikkan gejala atau pertanyaan Anda tentang hewan peliharaan, dan saya akan memberikan informasi yang relevan.\n",
            "Chatbot: Untuk menggunakan chatbot, cukup ketikkan gejala atau pertanyaan Anda tentang hewan peliharaan, dan saya akan memberikan informasi yang relevan.\n",
            "\n",
            "Anda: Apa fungsi utama dari fitur Emergency?\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Intent yang Diprediksi: ask_feature\n",
            "Entitas yang Diekstrak: []\n",
            "Intent yang Disesuaikan: ask_feature\n",
            "Input yang Dipreproses: fungsi utama fitur emergency\n",
            "Kemiripan Tertinggi: 1.0000000000000002\n",
            "Respon yang Dipilih: Fitur Emergency memungkinkan Anda melaporkan hewan terlantar atau sakit ke komunitas pecinta hewan terdekat untuk mendapatkan bantuan.\n",
            "Chatbot: Fitur Emergency memungkinkan Anda melaporkan hewan terlantar atau sakit ke komunitas pecinta hewan terdekat untuk mendapatkan bantuan.\n",
            "\n",
            "Anda: Apa tujuan dari fitur komunitas di aplikasi ini?\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "Intent yang Diprediksi: ask_feature\n",
            "Entitas yang Diekstrak: []\n",
            "Intent yang Disesuaikan: ask_feature\n",
            "Input yang Dipreproses: tuju fitur komunitas aplikasi\n",
            "Kemiripan Tertinggi: 1.0000000000000002\n",
            "Respon yang Dipilih: Fitur komunitas membantu Anda terhubung dengan organisasi pecinta hewan untuk berbagi informasi, bantuan, atau inisiatif kolaboratif.\n",
            "Chatbot: Fitur komunitas membantu Anda terhubung dengan organisasi pecinta hewan untuk berbagi informasi, bantuan, atau inisiatif kolaboratif.\n",
            "\n",
            "Anda: kucing saya muntah dan diare\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Intent yang Diprediksi: animal_health_issue\n",
            "Entitas yang Diekstrak: [{'entity': 'animal', 'value': 'kucing'}, {'entity': 'symptom', 'value': 'muntah'}, {'entity': 'symptom', 'value': 'diare'}]\n",
            "Intent yang Disesuaikan: animal_health_issue\n",
            "Input yang Dipreproses: kucing muntah diare\n",
            "Kemiripan Tertinggi: 0.4962473983292892\n",
            "Respon yang Dipilih: Berikan makanan ringan seperti nasi dan ayam rebus. Jika muntah terus terjadi, segera bawa ke dokter hewan untuk pemeriksaan.\n",
            "Chatbot: Berikan makanan ringan seperti nasi dan ayam rebus. Jika muntah terus terjadi, segera bawa ke dokter hewan untuk pemeriksaan.\n",
            "\n",
            "Anda: anjing saya matanya bengkak\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Intent yang Diprediksi: symptom_analysis_dog\n",
            "Entitas yang Diekstrak: [{'entity': 'animal', 'value': 'anjing'}, {'entity': 'symptom', 'value': 'mata'}, {'entity': 'symptom', 'value': 'bengkak'}]\n",
            "Intent yang Disesuaikan: symptom_analysis_dog\n",
            "Input yang Dipreproses: anjing mata bengkak\n",
            "Kemiripan Tertinggi: 0.41861040660560134\n",
            "Respon yang Dipilih: Kesulitan membuka mata dan mata berair bisa menjadi tanda iritasi atau infeksi. Bersihkan dengan kain lembut dan konsultasikan ke dokter hewan.\n",
            "Chatbot: Kesulitan membuka mata dan mata berair bisa menjadi tanda iritasi atau infeksi. Bersihkan dengan kain lembut dan konsultasikan ke dokter hewan.\n",
            "\n",
            "Anda: kucing saya demam dan flu\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Intent yang Diprediksi: medical_inquiry_cat\n",
            "Entitas yang Diekstrak: [{'entity': 'animal', 'value': 'kucing'}, {'entity': 'symptom', 'value': 'demam'}]\n",
            "Intent yang Disesuaikan: medical_inquiry_cat\n",
            "Input yang Dipreproses: kucing demam flu\n",
            "Kemiripan Tertinggi: 0.22216735617407662\n",
            "Respon yang Dipilih: Cek apakah kucing mengalami sakit pada kakinya atau lemas. Pastikan tidak ada cedera dan konsultasikan ke dokter hewan.\n",
            "Chatbot: Cek apakah kucing mengalami sakit pada kakinya atau lemas. Pastikan tidak ada cedera dan konsultasikan ke dokter hewan.\n",
            "\n",
            "Anda: apa itu toxoplasmosis\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "Intent yang Diprediksi: intro_chat\n",
            "Entitas yang Diekstrak: []\n",
            "Intent yang Disesuaikan: intro_chat\n",
            "Input yang Dipreproses: toxoplasmosis\n",
            "Kemiripan Tertinggi: 0.0\n",
            "Kemiripan di bawah threshold.\n",
            "Chatbot: Maaf, saya hanya diprogram untuk menjawab pertanyaan mengenai kucing dan anjing.\n",
            "\n",
            "Anda: AI itu apa\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "Intent yang Diprediksi: intro_chat\n",
            "Entitas yang Diekstrak: []\n",
            "Intent yang Disesuaikan: intro_chat\n",
            "Input yang Dipreproses: ai\n",
            "Kemiripan Tertinggi: 0.0\n",
            "Kemiripan di bawah threshold.\n",
            "Chatbot: Maaf, saya hanya diprogram untuk menjawab pertanyaan mengenai kucing dan anjing.\n",
            "\n",
            "Anda: anjing tetangga suka menggonggong\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "Intent yang Diprediksi: report_animal_noise\n",
            "Entitas yang Diekstrak: [{'entity': 'animal', 'value': 'anjing'}]\n",
            "Intent yang Disesuaikan: report_animal_noise\n",
            "Input yang Dipreproses: anjing tetangga suka gonggong\n",
            "Kemiripan Tertinggi: 0.49163917815096664\n",
            "Respon yang Dipilih: Coba bicarakan masalah ini dengan pemilik anjing. Jika tidak ada solusi, laporkan ke pengelola lingkungan.\n",
            "Chatbot: Coba bicarakan masalah ini dengan pemilik anjing. Jika tidak ada solusi, laporkan ke pengelola lingkungan.\n",
            "\n",
            "Anda: Saya melihat seekor anjing tua tanpa kalung di kompleks. Apa yang harus saya lakukan?\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Intent yang Diprediksi: found_stray_dog_street\n",
            "Entitas yang Diekstrak: [{'entity': 'animal', 'value': 'anjing'}, {'entity': 'animal', 'value': 'tua'}, {'entity': 'condition', 'value': 'kalung'}, {'entity': 'location', 'value': 'kompleks'}]\n",
            "Intent yang Disesuaikan: found_stray_dog_street\n",
            "Input yang Dipreproses: ekor anjing tua kalung kompleks laku\n",
            "Kemiripan Tertinggi: 1.0\n",
            "Respon yang Dipilih: Berikan air dan makanan, lalu coba cari informasi apakah ada pemilik yang kehilangan anjing.\n",
            "Chatbot: Berikan air dan makanan, lalu coba cari informasi apakah ada pemilik yang kehilangan anjing.\n",
            "\n",
            "Anda: Saya menemukan kucing dengan mata tertutup kotoran di depan pasar. Apa yang harus saya lakukan?\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Intent yang Diprediksi: found_cat_eye_problem\n",
            "Entitas yang Diekstrak: [{'entity': 'animal', 'value': 'kucing'}, {'entity': 'symptom', 'value': 'mata'}, {'entity': 'symptom', 'value': 'tutup'}, {'entity': 'symptom', 'value': 'kotor'}, {'entity': 'location', 'value': 'pasar'}]\n",
            "Intent yang Disesuaikan: found_cat_eye_problem\n",
            "Input yang Dipreproses: temu kucing mata tutup kotor pasar laku\n",
            "Kemiripan Tertinggi: 1.0\n",
            "Respon yang Dipilih: Bersihkan mata kucing dengan kapas lembut yang dibasahi air hangat, lalu bawa ke klinik hewan jika tidak membaik.\n",
            "Chatbot: Bersihkan mata kucing dengan kapas lembut yang dibasahi air hangat, lalu bawa ke klinik hewan jika tidak membaik.\n",
            "\n",
            "Anda: Apakah saya bisa membawa anjing ke dalam kereta api jarak jauh? Jika ya, apa yang harus disiapkan?\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "Intent yang Diprediksi: pet_transportation\n",
            "Entitas yang Diekstrak: [{'entity': 'animal', 'value': 'anjing'}, {'entity': 'condition', 'value': 'kereta'}, {'entity': 'condition', 'value': 'api'}, {'entity': 'location', 'value': 'jarak'}]\n",
            "Intent yang Disesuaikan: pet_transportation\n",
            "Input yang Dipreproses: bawa anjing kereta api jarak ya siap\n",
            "Kemiripan Tertinggi: 1.0\n",
            "Respon yang Dipilih: Hubungi operator kereta untuk memastikan kebijakan mereka. Siapkan dokumen vaksinasi dan kandang sesuai aturan.\n",
            "Chatbot: Hubungi operator kereta untuk memastikan kebijakan mereka. Siapkan dokumen vaksinasi dan kandang sesuai aturan.\n",
            "\n",
            "Anda: Saya ingin membawa kucing saya dalam perjalanan ke luar kota menggunakan pesawat. Apa saja yang perlu dipersiapkan?\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Intent yang Diprediksi: pet_transportation\n",
            "Entitas yang Diekstrak: [{'entity': 'animal', 'value': 'kucing'}, {'entity': 'location', 'value': 'jalan'}, {'entity': 'location', 'value': 'kota'}]\n",
            "Intent yang Disesuaikan: pet_transportation\n",
            "Input yang Dipreproses: bawa kucing jalan kota pesawat siap\n",
            "Kemiripan Tertinggi: 1.0\n",
            "Respon yang Dipilih: Pastikan kucing memiliki dokumen kesehatan, gunakan kandang yang sesuai, dan hubungi maskapai untuk informasi tambahan.\n",
            "Chatbot: Pastikan kucing memiliki dokumen kesehatan, gunakan kandang yang sesuai, dan hubungi maskapai untuk informasi tambahan.\n",
            "\n",
            "Anda: Kucing saya seperti atlet parkour, suka melompat ke rak dapur dan menjatuhkan barang. Bagaimana saya bisa menghentikannya?\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Intent yang Diprediksi: pet_behavior_issues\n",
            "Entitas yang Diekstrak: [{'entity': 'animal', 'value': 'kucing'}, {'entity': 'behavior', 'value': 'rak'}, {'entity': 'behavior', 'value': 'dapur'}, {'entity': 'behavior', 'value': 'jatuh'}]\n",
            "Intent yang Disesuaikan: pet_behavior_issues\n",
            "Input yang Dipreproses: kucing atlet parkour suka lompat rak dapur jatuh barang henti\n",
            "Kemiripan Tertinggi: 1.0\n",
            "Respon yang Dipilih: Pastikan area dapur tidak menarik bagi kucing, seperti dengan menyimpan makanan di tempat tertutup. Berikan mainan atau tempat melompat alternatif.\n",
            "Chatbot: Pastikan area dapur tidak menarik bagi kucing, seperti dengan menyimpan makanan di tempat tertutup. Berikan mainan atau tempat melompat alternatif.\n",
            "\n",
            "Anda: Saya melihat kucing di gang kecil yang terus mondar-mandir dengan ekspresi kebingungan\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Intent yang Diprediksi: found_confused_cat\n",
            "Entitas yang Diekstrak: [{'entity': 'animal', 'value': 'kucing'}, {'entity': 'condition', 'value': 'gang'}, {'entity': 'condition', 'value': 'mondarmandir'}]\n",
            "Intent yang Disesuaikan: found_confused_cat\n",
            "Input yang Dipreproses: kucing gang mondarmandir ekspresi bingung\n",
            "Kemiripan Tertinggi: 0.9901987176899206\n",
            "Respon yang Dipilih: Dekati kucing tersebut secara perlahan. Jika memungkinkan, cek apakah kucing memiliki tanda pengenal.\n",
            "Chatbot: Dekati kucing tersebut secara perlahan. Jika memungkinkan, cek apakah kucing memiliki tanda pengenal.\n",
            "\n",
            "Anda: Ada seekor anjing besar yang tampak sakit di depan kantor saya\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "Intent yang Diprediksi: found_animal\n",
            "Entitas yang Diekstrak: [{'entity': 'animal', 'value': 'anjing'}, {'entity': 'location', 'value': 'kantor'}]\n",
            "Intent yang Disesuaikan: found_animal\n",
            "Input yang Dipreproses: ekor anjing sakit kantor\n",
            "Kemiripan Tertinggi: 0.6507986747112224\n",
            "Respon yang Dipilih: Dekati anjing dengan hati-hati, berikan air atau makanan ringan, dan hubungi dokter hewan atau komunitas penyelamat.\n",
            "Chatbot: Dekati anjing dengan hati-hati, berikan air atau makanan ringan, dan hubungi dokter hewan atau komunitas penyelamat.\n",
            "\n",
            "Anda: pasar itu apa\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Intent yang Diprediksi: intro_chat\n",
            "Entitas yang Diekstrak: []\n",
            "Intent yang Disesuaikan: intro_chat\n",
            "Input yang Dipreproses: pasar\n",
            "Kemiripan Tertinggi: 0.0\n",
            "Kemiripan di bawah threshold.\n",
            "Chatbot: Maaf, saya hanya diprogram untuk menjawab pertanyaan mengenai kucing dan anjing.\n",
            "\n",
            "Anda: apa yang dimaksud dengan analisa fundamental\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "Intent yang Diprediksi: found_kitten_under_car\n",
            "Entitas yang Diekstrak: []\n",
            "Intent yang Disesuaikan: found_kitten_under_car\n",
            "Input yang Dipreproses: analisa fundamental\n",
            "Kemiripan Tertinggi: 0.0\n",
            "Kemiripan di bawah threshold.\n",
            "Chatbot: Maaf, mohon diperjelas apa yang Anda maksud.\n",
            "\n",
            "Anda: kamu tau fakta unik anjing tua\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Intent yang Diprediksi: fun_fact\n",
            "Entitas yang Diekstrak: [{'entity': 'animal', 'value': 'tua'}]\n",
            "Intent yang Disesuaikan: fun_fact\n",
            "Input yang Dipreproses: tau fakta unik anjing tua\n",
            "Kemiripan Tertinggi: 1.0\n",
            "Respon yang Dipilih: Fakta unik: Anjing tua sering kali lebih tenang dan lebih cenderung setia kepada pemiliknya dibandingkan anjing muda.\n",
            "Chatbot: Fakta unik: Anjing tua sering kali lebih tenang dan lebih cenderung setia kepada pemiliknya dibandingkan anjing muda.\n",
            "\n",
            "Anda: makasih ya\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n",
            "Intent yang Diprediksi: end_chat\n",
            "Entitas yang Diekstrak: []\n",
            "Intent yang Disesuaikan: end_chat\n",
            "Input yang Dipreproses: makasih ya\n",
            "Kemiripan Tertinggi: 1.0000000000000002\n",
            "Respon yang Dipilih: Sama-sama! Saya selalu siap membantu.\n",
            "Chatbot: Sama-sama! Saya selalu siap membantu.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir app\n",
        "!mv dataaa.json stopword_list_tala.txt data/\n",
        "!mv data app/\n",
        "!mv encoders app/\n",
        "!mv models app/"
      ],
      "metadata": {
        "id": "PeVFkVJj-vN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r allinone.zip app/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEOh-KWIB4Du",
        "outputId": "e556da0f-55aa-40db-cfe2-183291939a85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: app/ (stored 0%)\n",
            "  adding: app/models/ (stored 0%)\n",
            "  adding: app/models/model_intent.keras (deflated 8%)\n",
            "  adding: app/models/model_ner.keras (deflated 8%)\n",
            "  adding: app/data/ (stored 0%)\n",
            "  adding: app/data/vectorizer.pickle (deflated 51%)\n",
            "  adding: app/data/stopword_list_tala.txt (deflated 67%)\n",
            "  adding: app/data/dataaa.json (deflated 88%)\n",
            "  adding: app/encoders/ (stored 0%)\n",
            "  adding: app/encoders/tokenizer.pickle (deflated 44%)\n",
            "  adding: app/encoders/ner_label_encoder.pickle (deflated 44%)\n",
            "  adding: app/encoders/label_encoder.pickle (deflated 53%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cek semua library dan versinya\n",
        "!pip list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTZ6_zC73i2t",
        "outputId": "db187561-d20b-4f08-c081-98f9dd676f9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package                            Version\n",
            "---------------------------------- -------------------\n",
            "absl-py                            1.4.0\n",
            "accelerate                         1.1.1\n",
            "aiohappyeyeballs                   2.4.3\n",
            "aiohttp                            3.11.2\n",
            "aiosignal                          1.3.1\n",
            "alabaster                          1.0.0\n",
            "albucore                           0.0.19\n",
            "albumentations                     1.4.20\n",
            "altair                             4.2.2\n",
            "annotated-types                    0.7.0\n",
            "anyio                              3.7.1\n",
            "argon2-cffi                        23.1.0\n",
            "argon2-cffi-bindings               21.2.0\n",
            "array_record                       0.5.1\n",
            "arviz                              0.20.0\n",
            "astropy                            6.1.6\n",
            "astropy-iers-data                  0.2024.11.18.0.35.2\n",
            "astunparse                         1.6.3\n",
            "async-timeout                      4.0.3\n",
            "atpublic                           4.1.0\n",
            "attrs                              24.2.0\n",
            "audioread                          3.0.1\n",
            "autograd                           1.7.0\n",
            "babel                              2.16.0\n",
            "backcall                           0.2.0\n",
            "beautifulsoup4                     4.12.3\n",
            "bigframes                          1.27.0\n",
            "bigquery-magics                    0.4.0\n",
            "bleach                             6.2.0\n",
            "blinker                            1.9.0\n",
            "blis                               0.7.11\n",
            "blosc2                             2.7.1\n",
            "bokeh                              3.6.1\n",
            "Bottleneck                         1.4.2\n",
            "bqplot                             0.12.43\n",
            "branca                             0.8.0\n",
            "CacheControl                       0.14.1\n",
            "cachetools                         5.5.0\n",
            "catalogue                          2.0.10\n",
            "certifi                            2024.8.30\n",
            "cffi                               1.17.1\n",
            "chardet                            5.2.0\n",
            "charset-normalizer                 3.4.0\n",
            "chex                               0.1.87\n",
            "clarabel                           0.9.0\n",
            "click                              8.1.7\n",
            "cloudpathlib                       0.20.0\n",
            "cloudpickle                        3.1.0\n",
            "cmake                              3.30.5\n",
            "cmdstanpy                          1.2.4\n",
            "colorcet                           3.1.0\n",
            "colorlover                         0.3.0\n",
            "colour                             0.1.5\n",
            "community                          1.0.0b1\n",
            "confection                         0.1.5\n",
            "cons                               0.4.6\n",
            "contourpy                          1.3.1\n",
            "cryptography                       43.0.3\n",
            "cuda-python                        12.2.1\n",
            "cudf-cu12                          24.10.1\n",
            "cufflinks                          0.17.3\n",
            "cupy-cuda12x                       12.2.0\n",
            "cvxopt                             1.3.2\n",
            "cvxpy                              1.5.4\n",
            "cycler                             0.12.1\n",
            "cymem                              2.0.8\n",
            "Cython                             3.0.11\n",
            "dask                               2024.10.0\n",
            "datascience                        0.17.6\n",
            "db-dtypes                          1.3.1\n",
            "dbus-python                        1.2.18\n",
            "debugpy                            1.8.0\n",
            "decorator                          4.4.2\n",
            "defusedxml                         0.7.1\n",
            "Deprecated                         1.2.15\n",
            "diffusers                          0.31.0\n",
            "distro                             1.9.0\n",
            "dlib                               19.24.2\n",
            "dm-tree                            0.1.8\n",
            "docker-pycreds                     0.4.0\n",
            "docstring_parser                   0.16\n",
            "docutils                           0.21.2\n",
            "dopamine_rl                        4.0.9\n",
            "duckdb                             1.1.3\n",
            "earthengine-api                    1.2.0\n",
            "easydict                           1.13\n",
            "ecos                               2.0.14\n",
            "editdistance                       0.8.1\n",
            "eerepr                             0.0.4\n",
            "einops                             0.8.0\n",
            "en-core-web-sm                     3.7.1\n",
            "entrypoints                        0.4\n",
            "et_xmlfile                         2.0.0\n",
            "etils                              1.10.0\n",
            "etuples                            0.3.9\n",
            "eval_type_backport                 0.2.0\n",
            "exceptiongroup                     1.2.2\n",
            "fastai                             2.7.18\n",
            "fastcore                           1.7.20\n",
            "fastdownload                       0.0.7\n",
            "fastjsonschema                     2.20.0\n",
            "fastprogress                       1.0.3\n",
            "fastrlock                          0.8.2\n",
            "filelock                           3.16.1\n",
            "firebase-admin                     6.5.0\n",
            "Flask                              3.0.3\n",
            "flatbuffers                        24.3.25\n",
            "flax                               0.8.5\n",
            "folium                             0.18.0\n",
            "fonttools                          4.55.0\n",
            "frozendict                         2.4.6\n",
            "frozenlist                         1.5.0\n",
            "fsspec                             2024.10.0\n",
            "future                             1.0.0\n",
            "gast                               0.6.0\n",
            "gcsfs                              2024.10.0\n",
            "GDAL                               3.6.4\n",
            "gdown                              5.2.0\n",
            "geemap                             0.35.1\n",
            "gensim                             4.3.3\n",
            "geocoder                           1.38.1\n",
            "geographiclib                      2.0\n",
            "geopandas                          1.0.1\n",
            "geopy                              2.4.1\n",
            "gin-config                         0.5.0\n",
            "gitdb                              4.0.11\n",
            "GitPython                          3.1.43\n",
            "glob2                              0.7\n",
            "google                             2.0.3\n",
            "google-ai-generativelanguage       0.6.10\n",
            "google-api-core                    2.19.2\n",
            "google-api-python-client           2.151.0\n",
            "google-auth                        2.27.0\n",
            "google-auth-httplib2               0.2.0\n",
            "google-auth-oauthlib               1.2.1\n",
            "google-cloud-aiplatform            1.71.1\n",
            "google-cloud-bigquery              3.25.0\n",
            "google-cloud-bigquery-connection   1.16.1\n",
            "google-cloud-bigquery-storage      2.27.0\n",
            "google-cloud-bigtable              2.27.0\n",
            "google-cloud-core                  2.4.1\n",
            "google-cloud-datastore             2.20.1\n",
            "google-cloud-firestore             2.19.0\n",
            "google-cloud-functions             1.18.1\n",
            "google-cloud-iam                   2.16.1\n",
            "google-cloud-language              2.15.1\n",
            "google-cloud-pubsub                2.27.1\n",
            "google-cloud-resource-manager      1.13.1\n",
            "google-cloud-storage               2.8.0\n",
            "google-cloud-translate             3.17.0\n",
            "google-colab                       1.0.0\n",
            "google-crc32c                      1.6.0\n",
            "google-generativeai                0.8.3\n",
            "google-pasta                       0.2.0\n",
            "google-resumable-media             2.7.2\n",
            "googleapis-common-protos           1.66.0\n",
            "googledrivedownloader              0.4\n",
            "graphviz                           0.20.3\n",
            "greenlet                           3.1.1\n",
            "grpc-google-iam-v1                 0.13.1\n",
            "grpcio                             1.68.0\n",
            "grpcio-status                      1.62.3\n",
            "gspread                            6.0.2\n",
            "gspread-dataframe                  3.3.1\n",
            "gym                                0.25.2\n",
            "gym-notices                        0.0.8\n",
            "h11                                0.14.0\n",
            "h5netcdf                           1.4.1\n",
            "h5py                               3.12.1\n",
            "holidays                           0.61\n",
            "holoviews                          1.20.0\n",
            "html5lib                           1.1\n",
            "httpcore                           1.0.7\n",
            "httpimport                         1.4.0\n",
            "httplib2                           0.22.0\n",
            "httpx                              0.27.2\n",
            "huggingface-hub                    0.26.2\n",
            "humanize                           4.11.0\n",
            "hyperopt                           0.2.7\n",
            "ibis-framework                     9.2.0\n",
            "idna                               3.10\n",
            "imageio                            2.36.0\n",
            "imageio-ffmpeg                     0.5.1\n",
            "imagesize                          1.4.1\n",
            "imbalanced-learn                   0.12.4\n",
            "imgaug                             0.4.0\n",
            "immutabledict                      4.2.1\n",
            "importlib_metadata                 8.5.0\n",
            "importlib_resources                6.4.5\n",
            "imutils                            0.5.4\n",
            "inflect                            7.4.0\n",
            "iniconfig                          2.0.0\n",
            "intel-cmplr-lib-ur                 2025.0.0\n",
            "intel-openmp                       2025.0.0\n",
            "ipyevents                          2.0.2\n",
            "ipyfilechooser                     0.6.0\n",
            "ipykernel                          5.5.6\n",
            "ipyleaflet                         0.19.2\n",
            "ipyparallel                        8.8.0\n",
            "ipython                            7.34.0\n",
            "ipython-genutils                   0.2.0\n",
            "ipython-sql                        0.5.0\n",
            "ipytree                            0.2.2\n",
            "ipywidgets                         7.7.1\n",
            "itsdangerous                       2.2.0\n",
            "jax                                0.4.33\n",
            "jax-cuda12-pjrt                    0.4.33\n",
            "jax-cuda12-plugin                  0.4.33\n",
            "jaxlib                             0.4.33\n",
            "jeepney                            0.7.1\n",
            "jellyfish                          1.1.0\n",
            "jieba                              0.42.1\n",
            "Jinja2                             3.1.4\n",
            "jiter                              0.7.1\n",
            "joblib                             1.4.2\n",
            "jsonpatch                          1.33\n",
            "jsonpickle                         4.0.0\n",
            "jsonpointer                        3.0.0\n",
            "jsonschema                         4.23.0\n",
            "jsonschema-specifications          2024.10.1\n",
            "jupyter-client                     6.1.12\n",
            "jupyter-console                    6.1.0\n",
            "jupyter_core                       5.7.2\n",
            "jupyter-leaflet                    0.19.2\n",
            "jupyter-server                     1.24.0\n",
            "jupyterlab_pygments                0.3.0\n",
            "jupyterlab_widgets                 3.0.13\n",
            "kaggle                             1.6.17\n",
            "kagglehub                          0.3.4\n",
            "keras                              3.5.0\n",
            "keras-tuner                        1.4.7\n",
            "keyring                            23.5.0\n",
            "kiwisolver                         1.4.7\n",
            "kt-legacy                          1.0.5\n",
            "langchain                          0.3.7\n",
            "langchain-core                     0.3.19\n",
            "langchain-text-splitters           0.3.2\n",
            "langcodes                          3.4.1\n",
            "langsmith                          0.1.143\n",
            "language_data                      1.2.0\n",
            "launchpadlib                       1.10.16\n",
            "lazr.restfulclient                 0.14.4\n",
            "lazr.uri                           1.0.6\n",
            "lazy_loader                        0.4\n",
            "libclang                           18.1.1\n",
            "libcudf-cu12                       24.10.1\n",
            "librosa                            0.10.2.post1\n",
            "lightgbm                           4.5.0\n",
            "linkify-it-py                      2.0.3\n",
            "llvmlite                           0.43.0\n",
            "locket                             1.0.0\n",
            "logical-unification                0.4.6\n",
            "lxml                               5.3.0\n",
            "marisa-trie                        1.2.1\n",
            "Markdown                           3.7\n",
            "markdown-it-py                     3.0.0\n",
            "MarkupSafe                         3.0.2\n",
            "matplotlib                         3.8.0\n",
            "matplotlib-inline                  0.1.7\n",
            "matplotlib-venn                    1.1.1\n",
            "mdit-py-plugins                    0.4.2\n",
            "mdurl                              0.1.2\n",
            "miniKanren                         1.0.3\n",
            "missingno                          0.5.2\n",
            "mistune                            3.0.2\n",
            "mizani                             0.13.0\n",
            "mkl                                2025.0.0\n",
            "ml-dtypes                          0.4.1\n",
            "mlxtend                            0.23.3\n",
            "more-itertools                     10.5.0\n",
            "moviepy                            1.0.3\n",
            "mpmath                             1.3.0\n",
            "msgpack                            1.1.0\n",
            "multidict                          6.1.0\n",
            "multipledispatch                   1.0.0\n",
            "multitasking                       0.0.11\n",
            "murmurhash                         1.0.10\n",
            "music21                            9.3.0\n",
            "namex                              0.0.8\n",
            "natsort                            8.4.0\n",
            "nbclassic                          1.1.0\n",
            "nbclient                           0.10.0\n",
            "nbconvert                          7.16.4\n",
            "nbformat                           5.10.4\n",
            "ndindex                            1.9.2\n",
            "nest-asyncio                       1.6.0\n",
            "networkx                           3.4.2\n",
            "nibabel                            5.3.2\n",
            "nltk                               3.9.1\n",
            "notebook                           6.5.5\n",
            "notebook_shim                      0.2.4\n",
            "numba                              0.60.0\n",
            "numexpr                            2.10.1\n",
            "numpy                              1.26.4\n",
            "nvidia-cublas-cu12                 12.6.3.3\n",
            "nvidia-cuda-cupti-cu12             12.6.80\n",
            "nvidia-cuda-nvcc-cu12              12.6.77\n",
            "nvidia-cuda-runtime-cu12           12.6.77\n",
            "nvidia-cudnn-cu12                  9.5.1.17\n",
            "nvidia-cufft-cu12                  11.3.0.4\n",
            "nvidia-curand-cu12                 10.3.7.77\n",
            "nvidia-cusolver-cu12               11.7.1.2\n",
            "nvidia-cusparse-cu12               12.5.4.2\n",
            "nvidia-nccl-cu12                   2.23.4\n",
            "nvidia-nvjitlink-cu12              12.6.77\n",
            "nvtx                               0.2.10\n",
            "nx-cugraph-cu12                    24.10.0\n",
            "oauth2client                       4.1.3\n",
            "oauthlib                           3.2.2\n",
            "openai                             1.54.4\n",
            "opencv-contrib-python              4.10.0.84\n",
            "opencv-python                      4.10.0.84\n",
            "opencv-python-headless             4.10.0.84\n",
            "openpyxl                           3.1.5\n",
            "opentelemetry-api                  1.28.2\n",
            "opentelemetry-sdk                  1.28.2\n",
            "opentelemetry-semantic-conventions 0.49b2\n",
            "opt_einsum                         3.4.0\n",
            "optax                              0.2.4\n",
            "optree                             0.13.1\n",
            "orbax-checkpoint                   0.6.4\n",
            "orjson                             3.10.11\n",
            "osqp                               0.6.7.post3\n",
            "packaging                          24.2\n",
            "pandas                             2.2.2\n",
            "pandas-datareader                  0.10.0\n",
            "pandas-gbq                         0.24.0\n",
            "pandas-stubs                       2.2.2.240909\n",
            "pandocfilters                      1.5.1\n",
            "panel                              1.5.4\n",
            "param                              2.1.1\n",
            "parso                              0.8.4\n",
            "parsy                              2.1\n",
            "partd                              1.4.2\n",
            "pathlib                            1.0.1\n",
            "patsy                              1.0.1\n",
            "peewee                             3.17.8\n",
            "peft                               0.13.2\n",
            "pexpect                            4.9.0\n",
            "pickleshare                        0.7.5\n",
            "pillow                             11.0.0\n",
            "pip                                24.1.2\n",
            "platformdirs                       4.3.6\n",
            "plotly                             5.24.1\n",
            "plotnine                           0.14.1\n",
            "pluggy                             1.5.0\n",
            "polars                             1.9.0\n",
            "pooch                              1.8.2\n",
            "portpicker                         1.5.2\n",
            "preshed                            3.0.9\n",
            "prettytable                        3.12.0\n",
            "proglog                            0.1.10\n",
            "progressbar2                       4.5.0\n",
            "prometheus_client                  0.21.0\n",
            "promise                            2.3\n",
            "prompt_toolkit                     3.0.48\n",
            "propcache                          0.2.0\n",
            "prophet                            1.1.6\n",
            "proto-plus                         1.25.0\n",
            "protobuf                           4.25.5\n",
            "psutil                             5.9.5\n",
            "psycopg2                           2.9.10\n",
            "ptyprocess                         0.7.0\n",
            "py-cpuinfo                         9.0.0\n",
            "py4j                               0.10.9.7\n",
            "pyarrow                            17.0.0\n",
            "pyarrow-hotfix                     0.6\n",
            "pyasn1                             0.6.1\n",
            "pyasn1_modules                     0.4.1\n",
            "pycocotools                        2.0.8\n",
            "pycparser                          2.22\n",
            "pydantic                           2.9.2\n",
            "pydantic_core                      2.23.4\n",
            "pydata-google-auth                 1.8.2\n",
            "pydot                              3.0.2\n",
            "pydotplus                          2.0.2\n",
            "PyDrive                            1.3.1\n",
            "PyDrive2                           1.21.1\n",
            "pyerfa                             2.0.1.5\n",
            "pygame                             2.6.1\n",
            "pygit2                             1.16.0\n",
            "Pygments                           2.18.0\n",
            "PyGObject                          3.42.1\n",
            "PyJWT                              2.10.0\n",
            "pylibcudf-cu12                     24.10.1\n",
            "pylibcugraph-cu12                  24.10.0\n",
            "pylibraft-cu12                     24.10.0\n",
            "pymc                               5.18.2\n",
            "pymystem3                          0.2.0\n",
            "pynvjitlink-cu12                   0.4.0\n",
            "pyogrio                            0.10.0\n",
            "PyOpenGL                           3.1.7\n",
            "pyOpenSSL                          24.2.1\n",
            "pyparsing                          3.2.0\n",
            "pyperclip                          1.9.0\n",
            "pyproj                             3.7.0\n",
            "pyshp                              2.3.1\n",
            "PySocks                            1.7.1\n",
            "pyspark                            3.5.3\n",
            "pytensor                           2.26.3\n",
            "pytest                             8.3.3\n",
            "python-apt                         0.0.0\n",
            "python-box                         7.2.0\n",
            "python-dateutil                    2.8.2\n",
            "python-louvain                     0.16\n",
            "python-slugify                     8.0.4\n",
            "python-utils                       3.9.0\n",
            "pytz                               2024.2\n",
            "pyviz_comms                        3.0.3\n",
            "PyYAML                             6.0.2\n",
            "pyzmq                              24.0.1\n",
            "qdldl                              0.1.7.post4\n",
            "RapidFuzz                          3.10.1\n",
            "ratelim                            0.1.6\n",
            "referencing                        0.35.1\n",
            "regex                              2024.9.11\n",
            "requests                           2.32.3\n",
            "requests-oauthlib                  1.3.1\n",
            "requests-toolbelt                  1.0.0\n",
            "requirements-parser                0.9.0\n",
            "rich                               13.9.4\n",
            "rmm-cu12                           24.10.0\n",
            "rpds-py                            0.21.0\n",
            "rpy2                               3.4.2\n",
            "rsa                                4.9\n",
            "safetensors                        0.4.5\n",
            "Sastrawi                           1.0.1\n",
            "scikit-image                       0.24.0\n",
            "scikit-learn                       1.5.2\n",
            "scipy                              1.13.1\n",
            "scooby                             0.10.0\n",
            "scs                                3.2.7\n",
            "seaborn                            0.13.2\n",
            "SecretStorage                      3.3.1\n",
            "Send2Trash                         1.8.3\n",
            "sentence-transformers              3.2.1\n",
            "sentencepiece                      0.2.0\n",
            "sentry-sdk                         2.18.0\n",
            "seqeval                            1.2.2\n",
            "setproctitle                       1.3.4\n",
            "setuptools                         75.1.0\n",
            "shap                               0.46.0\n",
            "shapely                            2.0.6\n",
            "shellingham                        1.5.4\n",
            "simple-parsing                     0.1.6\n",
            "six                                1.16.0\n",
            "sklearn-pandas                     2.2.0\n",
            "slicer                             0.0.8\n",
            "smart-open                         7.0.5\n",
            "smmap                              5.0.1\n",
            "sniffio                            1.3.1\n",
            "snowballstemmer                    2.2.0\n",
            "soundfile                          0.12.1\n",
            "soupsieve                          2.6\n",
            "soxr                               0.5.0.post1\n",
            "spacy                              3.7.5\n",
            "spacy-legacy                       3.0.12\n",
            "spacy-loggers                      1.0.5\n",
            "Sphinx                             8.1.3\n",
            "sphinxcontrib-applehelp            2.0.0\n",
            "sphinxcontrib-devhelp              2.0.0\n",
            "sphinxcontrib-htmlhelp             2.1.0\n",
            "sphinxcontrib-jsmath               1.0.1\n",
            "sphinxcontrib-qthelp               2.0.0\n",
            "sphinxcontrib-serializinghtml      2.0.0\n",
            "SQLAlchemy                         2.0.36\n",
            "sqlglot                            25.1.0\n",
            "sqlparse                           0.5.2\n",
            "srsly                              2.4.8\n",
            "stanio                             0.5.1\n",
            "statsmodels                        0.14.4\n",
            "StrEnum                            0.4.15\n",
            "stringzilla                        3.10.10\n",
            "sympy                              1.13.1\n",
            "tables                             3.10.1\n",
            "tabulate                           0.9.0\n",
            "tbb                                2022.0.0\n",
            "tcmlib                             1.2.0\n",
            "tenacity                           9.0.0\n",
            "tensorboard                        2.17.1\n",
            "tensorboard-data-server            0.7.2\n",
            "tensorflow                         2.17.1\n",
            "tensorflow-datasets                4.9.7\n",
            "tensorflow-hub                     0.16.1\n",
            "tensorflow-io-gcs-filesystem       0.37.1\n",
            "tensorflow-metadata                1.13.1\n",
            "tensorflow-probability             0.24.0\n",
            "tensorstore                        0.1.68\n",
            "termcolor                          2.5.0\n",
            "terminado                          0.18.1\n",
            "text-unidecode                     1.3\n",
            "textblob                           0.17.1\n",
            "tf_keras                           2.17.0\n",
            "tf-slim                            1.1.0\n",
            "thinc                              8.2.5\n",
            "threadpoolctl                      3.5.0\n",
            "tifffile                           2024.9.20\n",
            "timm                               1.0.11\n",
            "tinycss2                           1.4.0\n",
            "tokenizers                         0.20.3\n",
            "toml                               0.10.2\n",
            "tomli                              2.1.0\n",
            "toolz                              0.12.1\n",
            "torch                              2.5.1+cu121\n",
            "torchaudio                         2.5.1+cu121\n",
            "torchsummary                       1.5.1\n",
            "torchvision                        0.20.1+cu121\n",
            "tornado                            6.3.3\n",
            "tqdm                               4.66.6\n",
            "traitlets                          5.7.1\n",
            "traittypes                         0.2.1\n",
            "transformers                       4.46.2\n",
            "tweepy                             4.14.0\n",
            "typeguard                          4.4.1\n",
            "typer                              0.13.0\n",
            "types-pytz                         2024.2.0.20241003\n",
            "types-setuptools                   75.5.0.20241122\n",
            "typing_extensions                  4.12.2\n",
            "tzdata                             2024.2\n",
            "tzlocal                            5.2\n",
            "uc-micro-py                        1.0.3\n",
            "umf                                0.9.0\n",
            "uritemplate                        4.1.1\n",
            "urllib3                            2.2.3\n",
            "vega-datasets                      0.9.0\n",
            "wadllib                            1.3.6\n",
            "wandb                              0.18.7\n",
            "wasabi                             1.1.3\n",
            "wcwidth                            0.2.13\n",
            "weasel                             0.4.1\n",
            "webcolors                          24.11.1\n",
            "webencodings                       0.5.1\n",
            "websocket-client                   1.8.0\n",
            "Werkzeug                           3.1.3\n",
            "wheel                              0.45.0\n",
            "widgetsnbextension                 3.6.10\n",
            "wordcloud                          1.9.4\n",
            "wrapt                              1.16.0\n",
            "xarray                             2024.10.0\n",
            "xarray-einstats                    0.8.0\n",
            "xgboost                            2.1.2\n",
            "xlrd                               2.0.1\n",
            "xyzservices                        2024.9.0\n",
            "yarl                               1.17.2\n",
            "yellowbrick                        1.5\n",
            "yfinance                           0.2.49\n",
            "zipp                               3.21.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_seq_length"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUqGwd-_3jdU",
        "outputId": "3ab8cb17-5c3f-4345-e0e3-f623de291863"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1eZTMoaCApEa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}